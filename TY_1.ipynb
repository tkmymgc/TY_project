{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# notebook to analyze axon data after suite2p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import savgol_filter\n",
    "from matplotlib import mlab\n",
    "from scipy.signal import detrend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F=np.load('F.npy')\n",
    "iscell=np.load('iscell.npy',allow_pickle=True)[:,0]\n",
    "stat=np.load('stat.npy',allow_pickle=True)\n",
    "\n",
    "F.shape, iscell.shape, stat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the cell ids\n",
    "ncells=len(stat)\n",
    "cell_ids = np.arange(ncells)\n",
    "\n",
    "#detect trace data of cells\n",
    "condition = np.mod(iscell, 2)==1\n",
    "cells=np.extract(condition,cell_ids)\n",
    "F_cell=F[cells,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate each dff and mean dff from each dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = np.arange(len(F_cell))[::1]  \n",
    "dff_f_each = np.empty(shape=F_cell.shape)\n",
    "for roi in rois:\n",
    "    meanF=F_cell[roi]\n",
    "    meanF0=np.percentile(meanF, 8)\n",
    "    mean_dff = 100*(meanF-meanF0)/meanF0\n",
    "    mean_dff_f = savgol_filter(mean_dff,50,3)\n",
    "    index = roi-1\n",
    "    dff_f_each[index] = mean_dff_f\n",
    "\n",
    "dff_f_each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_dff=0\n",
    "for roi in rois:\n",
    "    sum_dff=sum_dff+dff_f_each[roi]\n",
    "dff_f_mean_from_each_dff=sum_dff/len(F_cell)\n",
    "dff_f_mean_from_each_dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('dff_f_each.npy',dff_f_each)\n",
    "np.save('dff_f_mean_from_each_dff.npy',dff_f_mean_from_each_dff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_f_each=np.load('dff_f_each.npy')\n",
    "dff_f_mean_from_each_dff=np.load('dff_f_mean_from_each_dff.npy')\n",
    "dff_f_each.shape,dff_f_mean_from_each_dff.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### detect the time of teleport and switch env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load downsampled behavioral data\n",
    "df_downsample=pd.read_csv('df_downsample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the time teleport back\n",
    "n = np.array(range(0,len(df_downsample)-1,1))\n",
    "teleport_list=[]\n",
    "for u in n: \n",
    "    if df_downsample.Position[u]-df_downsample.Position[u+1] > 5:\n",
    "        if df_downsample.Position[u] > 5:\n",
    "            teleport_list.append(u)\n",
    "                  \n",
    "teleport_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "teleport_list_230706_C7=np.array(teleport_list)\n",
    "np.save('teleport_list_240804_C20.npy',teleport_list_230706_C7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9386\n",
      "28491\n"
     ]
    }
   ],
   "source": [
    "# Calculating the cell swicthing environment\n",
    "n = np.array(range(0,len(df_downsample)-1,1))\n",
    "for u in n: \n",
    "    if abs(df_downsample.Environment[u+1]-df_downsample.Environment[u]) > 1:\n",
    "        print(u+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "switch1=9386\n",
    "switch2=28491"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teleport_list.index(9380)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9380"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teleport_list[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teleport_list.index(28485)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28485"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teleport_list[55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "switch_heatmap1=teleport_list.index(9380)-0.5\n",
    "switch_heatmap2=teleport_list.index(28485)-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>switch1</th>\n",
       "      <th>switch2</th>\n",
       "      <th>switch_heatmap1</th>\n",
       "      <th>switch_heatmap2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9386</td>\n",
       "      <td>28491</td>\n",
       "      <td>20.5</td>\n",
       "      <td>54.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   switch1  switch2  switch_heatmap1  switch_heatmap2\n",
       "0     9386    28491             20.5             54.5"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the column names\n",
    "column_names = [\"switch1\", \"switch2\", \"switch_heatmap1\", \"switch_heatmap2\"]\n",
    "\n",
    "# Organize switch values\n",
    "data = {\n",
    "    \"switch1\": switch1,  # Replace value1 with your actual value\n",
    "    \"switch2\": switch2,  # Replace value2 with your actual value\n",
    "    \"switch_heatmap1\": switch_heatmap1,  # Replace value3 with your actual value\n",
    "    \"switch_heatmap2\": switch_heatmap2,  # Replace value4 with your actual value\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "switch_240605_C14H = pd.DataFrame(data,index=[0])\n",
    "\n",
    "# Display the DataFrame\n",
    "switch_240605_C14H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "switch_240605_C14H.to_csv('switch_240804_C20.csv',index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspection of signals by plotting graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean_trace + Velocity\n",
    "fig, ax1 = plt.subplots(figsize=[13,5])\n",
    "plt.suptitle(\"240804_C20_mean_trace_env_swicth\",y=1.1, fontsize='xx-large')    \n",
    "    \n",
    "ax1.plot(df_downsample.Time, df_downsample.Velocity,   color='#0344DF', linewidth=0.1)\n",
    "\n",
    "plt.axvline(x=df_downsample.Time[switch1])\n",
    "plt.axvline(x=df_downsample.Time[switch2])\n",
    "ax1.axvspan(0,df_downsample.Time[switch1-1], facecolor='lightblue', alpha=0.65)\n",
    "ax1.axvspan(df_downsample.Time[switch1+1],df_downsample.Time[switch2-1], facecolor='chartreuse', alpha=0.4)\n",
    "ax1.axvspan(df_downsample.Time[switch2+1],df_downsample.Time[len(dff_f_mean_from_each_dff)-1], facecolor='lightblue', alpha=0.4)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(df_downsample.Time, dff_f_mean_from_each_dff, color='tab:orange',label=\"Mean Trace\", linewidth=0.6)\n",
    "\n",
    "plt.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    \n",
    "plt.legend(bbox_to_anchor=(0.93, 1.1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check speed across environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average speed\n",
    "\n",
    "br1=df_downsample.Velocity[:switch1-1].mean()\n",
    "br2=df_downsample.Velocity[switch1+1:switch2-1].mean()\n",
    "br3=df_downsample.Velocity[switch2+1:].mean()\n",
    "\n",
    "print(br1)\n",
    "print(br2)\n",
    "print(br3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Monitoring running speed across environments\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "plt.bar(0,br1, color ='blue', alpha=0.4, \n",
    "        edgecolor ='grey', label ='env1') \n",
    "plt.bar(1,br2,  color ='green', alpha=0.4, \n",
    "        edgecolor ='grey', label ='env2') \n",
    "plt.bar(2,br3,  color ='midnightblue', alpha=0.4, \n",
    "        edgecolor ='grey', label ='returned env1') \n",
    "\n",
    "plt.suptitle(\"240804_C20_mean_velocity\",y=1.0, fontsize='xx-large')\n",
    "\n",
    "#remove x ticks\n",
    "plt.tick_params(\n",
    "    axis='x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False) \n",
    "\n",
    "legend_handles = [Line2D([0], [0], color='blue', alpha=0.75,label='familiar'),\n",
    "                  Line2D([0], [0], color='green', alpha=0.75,label='novel'),\n",
    "                  Line2D([0], [0], color='midnightblue', alpha=0.75,label='familiar_returned')]\n",
    "\n",
    "# Add the legend with custom handles and labels\n",
    "plt.legend(handles=legend_handles,bbox_to_anchor=(1, 1.1))\n",
    "\n",
    "\n",
    "plt.text(-0.1, br1, str(round(br1, 3)))\n",
    "plt.text(0.9, br2, str(round(br2, 3)))\n",
    "plt.text(1.9, br3, str(round(br3, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# predict dff with log fit to speed vs dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "velocity_f = savgol_filter(df_downsample.Velocity,50,3) # savgol_filter for velocity\n",
    "velocity_f=pd.DataFrame(velocity_f)\n",
    "velocity_f_positive=velocity_f[0]-velocity_f[0].min()+0.0000001 # Adjust velocity by deducting min_vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for average trace\n",
    "pd_dff_f_mean_eachdff=pd.DataFrame(dff_f_mean_from_each_dff)[0]\n",
    "dff_f_mean_env1=pd_dff_f_mean_eachdff[:switch1-1] \n",
    "scale_factor = 100 / (np.percentile(dff_f_mean_env1,90) - min(dff_f_mean_env1))\n",
    "rescaled_dff = (pd_dff_f_mean_eachdff - min(dff_f_mean_env1)) * scale_factor\n",
    "\n",
    "x = velocity_f_positive[:switch1]  # Reverse the order\n",
    "y = rescaled_dff[:switch1]   # Reverse the order   \n",
    "coeffs = np.polyfit(np.log(x), y, 1)\n",
    "x = velocity_f_positive\n",
    "ypred = np.polyval(coeffs, np.log(x))\n",
    "novelty_average=rescaled_dff-ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       -91.166301\n",
       "1       -80.656885\n",
       "2       -70.996820\n",
       "3       -62.156345\n",
       "4       -54.105476\n",
       "           ...    \n",
       "37979   -24.829087\n",
       "37980   -24.122907\n",
       "37981   -23.240882\n",
       "37982   -22.145291\n",
       "37983   -20.795990\n",
       "Name: 0, Length: 37984, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Actual dff data - prediction (normalized)\n",
    "pd_dff_f_mean_eachdff=pd.DataFrame(dff_f_mean_from_each_dff)[0]\n",
    "dff_f_mean_env1=pd_dff_f_mean_eachdff[:switch1-1] \n",
    "scale_factor = 100 / (np.percentile(dff_f_mean_env1,90) - min(dff_f_mean_env1))\n",
    "rescaled_dff = (pd_dff_f_mean_eachdff - min(dff_f_mean_env1)) * scale_factor\n",
    "\n",
    "x = velocity_f_positive[:switch1]  # Reverse the order\n",
    "y = rescaled_dff[:switch1]   # Reverse the order   \n",
    "coeffs = np.polyfit(np.log(x), y, 1)\n",
    "x = velocity_f_positive\n",
    "ypred = np.polyval(coeffs, np.log(x))\n",
    "novelty_average=rescaled_dff-ypred\n",
    "np.save('novelty_average_240804_C20',novelty_average)\n",
    "novelty_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min_average of the prediction error in env1\n",
    "novelty_average_minute_familiar = []\n",
    "\n",
    "for n in range(1,10+1):\n",
    "    if n == 1:\n",
    "        # Compute the absolute difference between the 'Time' column and 1\n",
    "        abs_diff = np.abs(df_downsample.Time - n*60)\n",
    "        # Find the index of the minimum value in the absolute difference series\n",
    "        X = np.argmin(abs_diff)\n",
    "        novelty_minute=novelty_average[:switch1][:X+1].mean()\n",
    "        novelty_average_minute_familiar.append(novelty_minute) \n",
    "    else:\n",
    "        abs_diff1 = np.abs(df_downsample.Time - (n-1)*60)\n",
    "        X1 = np.argmin(abs_diff1)\n",
    "        abs_diff2 = np.abs(df_downsample.Time - n*60)\n",
    "        X2 = np.argmin(abs_diff2)\n",
    "        novelty_minute=novelty_average[:switch1][X1:X2+1].mean()\n",
    "        novelty_average_minute_familiar.append(novelty_minute) \n",
    "        \n",
    "print(novelty_average_minute_familiar, len(novelty_average_minute_familiar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min_average of the prediction error in env2\n",
    "novelty_average_minute_novel = []\n",
    "\n",
    "for n in range(1,20+1):\n",
    "    if n == 1:\n",
    "        # Compute the absolute difference between the 'Time' column and 1\n",
    "        abs_diff = np.abs(df_downsample.Time - n*60)\n",
    "        # Find the index of the minimum value in the absolute difference series\n",
    "        X = np.argmin(abs_diff)\n",
    "        novelty_minute=novelty_average[switch1:switch2][:X+1].mean()\n",
    "        novelty_average_minute_novel.append(novelty_minute) \n",
    "    else:\n",
    "        abs_diff1 = np.abs(df_downsample.Time - (n-1)*60)\n",
    "        X1 = np.argmin(abs_diff1)\n",
    "        abs_diff2 = np.abs(df_downsample.Time - n*60)\n",
    "        X2 = np.argmin(abs_diff2)\n",
    "        novelty_minute=novelty_average[switch1:switch2][X1:X2+1].mean()\n",
    "        novelty_average_minute_novel.append(novelty_minute) \n",
    "        \n",
    "print(novelty_average_minute_novel, len(novelty_average_minute_novel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min_average of the prediction error in returned env1\n",
    "novelty_average_minute_Rfamiliar = []\n",
    "\n",
    "for n in range(1,10+1):\n",
    "    if n == 1:\n",
    "        # Compute the absolute difference between the 'Time' column and 1\n",
    "        abs_diff = np.abs(df_downsample.Time - n*60)\n",
    "        # Find the index of the minimum value in the absolute difference series\n",
    "        X = np.argmin(abs_diff)\n",
    "        novelty_minute=novelty_average[switch2:][:X+1].mean()\n",
    "        novelty_average_minute_Rfamiliar.append(novelty_minute) \n",
    "    else:\n",
    "        abs_diff1 = np.abs(df_downsample.Time - (n-1)*60)\n",
    "        X1 = np.argmin(abs_diff1)\n",
    "        abs_diff2 = np.abs(df_downsample.Time - n*60)\n",
    "        X2 = np.argmin(abs_diff2)\n",
    "        novelty_minute=novelty_average[switch2:][X1:X2+1].mean()\n",
    "        novelty_average_minute_Rfamiliar.append(novelty_minute) \n",
    "        \n",
    "print(novelty_average_minute_Rfamiliar, len(novelty_average_minute_Rfamiliar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "novelty_average=np.load('novelty_average_240804_C20.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('novelty_average_minute_familiar_240804_C20',novelty_average_minute_familiar)\n",
    "np.save('novelty_average_minute_novel_240804_C20',novelty_average_minute_novel)\n",
    "np.save('novelty_average_minute_Rfamiliar_240804_C20',novelty_average_minute_Rfamiliar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot speed vs prediction error in env1\n",
    "from matplotlib.colors import ListedColormap\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "# set the data\n",
    "x = velocity_f_positive[switch1-2:0:-1]  # Reverse the order\n",
    "y = rescaled_dff[switch1-2:0:-1]  # Reverse the order \n",
    "\n",
    "spectral = plt.cm.get_cmap('Spectral')\n",
    "half_spectral = ListedColormap(spectral(np.linspace(0, 0.5, 256)))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[5.4,5])\n",
    "scatter=ax.scatter(x, y, c=df_downsample.Time[switch1-2:0:-1], s=1, cmap=half_spectral)\n",
    "plt.ylabel(\"normalized dF/F\", fontsize=14)\n",
    "plt.xlabel(\"Velocity\", fontsize=14)\n",
    "ax.tick_params(axis='y', labelsize=14)\n",
    "ax.tick_params(axis='x', labelsize=14)\n",
    "plt.ylim(0,150)\n",
    "plt.plot(x, ypred[switch1-2:0:-1], color=\"red\")     # regression line\n",
    "\n",
    "axins = inset_axes(ax,\n",
    "                   width=\"3%\",  # width of the colorbar\n",
    "                   height=\"50%\",  # height of the colorbar\n",
    "                   loc='center right',\n",
    "                   bbox_to_anchor=(0.1, 0.0, 1, 1),\n",
    "                   bbox_transform=ax.transAxes,\n",
    "                   borderpad=0,\n",
    "                   )\n",
    "cb = plt.colorbar(scatter, cax=axins)\n",
    "cb.set_label('Time',rotation=270, fontsize=14)\n",
    "tick_locs = [df_downsample.Time[0],df_downsample.Time[switch1-1]]  # Adjust these based on your data range\n",
    "tick_lbls = ['Start','End']\n",
    "cb.ax.set_yticks(tick_locs)    # Set the tick locations\n",
    "cb.ax.set_yticklabels(tick_lbls, fontsize=14)  # Set the tick labels\n",
    "cb.ax.invert_yaxis()# Reverse the direction of the colorbar\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot speed vs prediction error in env2\n",
    "x = velocity_f_positive[switch2-2:switch1:-1]  # Reverse the order\n",
    "y = rescaled_dff[switch2-2:switch1:-1]   # Reverse the order   \n",
    "\n",
    "fig, ax = plt.subplots(figsize=[5.4,5])\n",
    "scatter=ax.scatter(x, y, c=df_downsample.Time[switch2-2:switch1:-1], s=0.6, cmap='Spectral')\n",
    "plt.ylabel(\"normalized dF/F\", fontsize=14)\n",
    "plt.xlabel(\"Velocity\", fontsize=14)\n",
    "ax.tick_params(axis='y', labelsize=14)\n",
    "ax.tick_params(axis='x', labelsize=14)\n",
    "plt.ylim(0,150)\n",
    "plt.plot(x, ypred[switch2-2:switch1:-1], color=\"red\")     # regression line\n",
    "\n",
    "axins = inset_axes(ax,\n",
    "                   width=\"3%\",  # width of the colorbar\n",
    "                   height=\"100%\",  # height of the colorbar\n",
    "                   loc='center right',\n",
    "                   bbox_to_anchor=(0.1, 0.0, 1, 1),\n",
    "                   bbox_transform=ax.transAxes,\n",
    "                   borderpad=0,\n",
    "                   )\n",
    "cb = plt.colorbar(scatter, cax=axins)\n",
    "cb.set_label('Time',rotation=270, fontsize=14,labelpad=20)\n",
    "mid_point=(df_downsample.Time[switch2-1]-df_downsample.Time[switch1+1])/2+df_downsample.Time[switch1+1]\n",
    "tick_locs = [df_downsample.Time[switch1+1],mid_point, df_downsample.Time[switch2-1]]  # Adjust these based on your data range\n",
    "tick_lbls = ['0 min','10 min','20 min']\n",
    "cb.ax.set_yticks(tick_locs)    # Set the tick locations\n",
    "cb.ax.set_yticklabels(tick_lbls, fontsize=14)  # Set the tick labels\n",
    "cb.ax.invert_yaxis()# Reverse the direction of the colorbar\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot speed vs prediction error in returned env1\n",
    "x = velocity_f_positive[len(velocity_f_positive)-1:switch2:-1]  # Reverse the order\n",
    "y = rescaled_dff[len(velocity_f_positive)-1:switch2:-1]  # Reverse the order \n",
    "\n",
    "spectral = plt.cm.get_cmap('Spectral')\n",
    "half_spectral = ListedColormap(spectral(np.linspace(0, 0.5, 256)))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[5.4,5])\n",
    "scatter=ax.scatter(x, y, c=df_downsample.Time[len(velocity_f_positive)-1:switch2:-1], s=1, cmap=half_spectral)\n",
    "\n",
    "plt.ylabel(\"normalized dF/F\", fontsize=14)\n",
    "plt.xlabel(\"Velocity\", fontsize=14)\n",
    "ax.tick_params(axis='y', labelsize=14)\n",
    "ax.tick_params(axis='x', labelsize=14)\n",
    "plt.ylim(0,150)\n",
    "plt.plot(x, ypred[len(velocity_f_positive)-1:switch2:-1], color=\"red\")     # regression line\n",
    "\n",
    "axins = inset_axes(ax,\n",
    "                   width=\"3%\",  # width of the colorbar\n",
    "                   height=\"50%\",  # height of the colorbar\n",
    "                   loc='center right',\n",
    "                   bbox_to_anchor=(0.1, 0.0, 1, 1),\n",
    "                   bbox_transform=ax.transAxes,\n",
    "                   borderpad=0,\n",
    "                   )\n",
    "cb = plt.colorbar(scatter, cax=axins)\n",
    "cb.set_label('Time',rotation=270, fontsize=14)\n",
    "tick_locs = [df_downsample.Time[switch2+1],df_downsample.Time.iloc[-1]]  # Adjust these based on your data range\n",
    "tick_lbls = ['Start','End']\n",
    "cb.ax.set_yticks(tick_locs)    # Set the tick locations\n",
    "cb.ax.set_yticklabels(tick_lbls, fontsize=14)  # Set the tick labels\n",
    "cb.ax.invert_yaxis()# Reverse the direction of the colorbar\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xcorr_average_minute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define cross-correlation with manual set lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.lib.stride_tricks import as_strided\n",
    "\n",
    "\n",
    "def _check_arg(x, xname):\n",
    "    x = np.asarray(x)\n",
    "    if x.ndim != 1:\n",
    "        raise ValueError('%s must be one-dimensional.' % xname)\n",
    "    return x\n",
    "\n",
    "def autocorrelation(x, maxlag):\n",
    "    \"\"\"\n",
    "    Autocorrelation with a maximum number of lags.\n",
    "\n",
    "    `x` must be a one-dimensional numpy array.\n",
    "\n",
    "    This computes the same result as\n",
    "        numpy.correlate(x, x, mode='full')[len(x)-1:len(x)+maxlag]\n",
    "\n",
    "    The return value has length maxlag + 1.\n",
    "    \"\"\"\n",
    "    x = _check_arg(x, 'x')\n",
    "    p = np.pad(x.conj(), maxlag, mode='constant')\n",
    "    T = as_strided(p[maxlag:], shape=(maxlag+1, len(x) + maxlag),\n",
    "                   strides=(-p.strides[0], p.strides[0]))\n",
    "    return T.dot(p[maxlag:].conj())\n",
    "\n",
    "\n",
    "def crosscorrelation(x, y, maxlag):\n",
    "    \"\"\"\n",
    "    Cross correlation with a maximum number of lags.\n",
    "\n",
    "    `x` and `y` must be one-dimensional numpy arrays with the same length.\n",
    "\n",
    "    This computes the same result as\n",
    "        numpy.correlate(x, y, mode='full')[len(a)-maxlag-1:len(a)+maxlag]\n",
    "\n",
    "    The return vaue has length 2*maxlag + 1.\n",
    "    \"\"\"\n",
    "    x = _check_arg(x, 'x')\n",
    "    y = _check_arg(y, 'y')\n",
    "    py = np.pad(y.conj(), 2*maxlag, mode='constant')\n",
    "    T = as_strided(py[2*maxlag:], shape=(2*maxlag+1, len(y) + 2*maxlag),\n",
    "                   strides=(-py.strides[0], py.strides[0]))\n",
    "    px = np.pad(x, maxlag, mode='constant')\n",
    "    return T.dot(px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min_scale_correlation to speed in env1\n",
    "xcorr_average_minute_familiar = []\n",
    "\n",
    "for n in range(1,10+1):\n",
    "    if n == 1:\n",
    "        # Compute the absolute difference between the 'Time' column and 1\n",
    "        abs_diff = np.abs(df_downsample.Time - n*60)\n",
    "        # Find the index of the minimum value in the absolute difference series\n",
    "        X = np.argmin(abs_diff)\n",
    "        data1 = dff_f_mean_from_each_dff[:switch1][:X+1]\n",
    "        data2 = velocity_f_positive[:switch1][:X+1]\n",
    "        # Detrend the data\n",
    "        detrended_data1 = detrend(data1)\n",
    "        detrended_data2 = detrend(data2)\n",
    "        # Calculate cross-correlation\n",
    "        cross_corr = crosscorrelation(detrended_data1, detrended_data2, 15) #15 frames~ 1sec lag\n",
    "        # Normalize the cross-correlation to range from -1.0 to 1.0\n",
    "        normalized_corr = cross_corr / np.sqrt(np.sum(detrended_data1 ** 2) * np.sum(detrended_data2 ** 2))\n",
    "        # Find the maximum correlation coefficient\n",
    "        max_corr_coefficient = np.max(normalized_corr)\n",
    "        xcorr_average_minute_familiar.append(max_corr_coefficient) \n",
    "    else:\n",
    "        abs_diff1 = np.abs(df_downsample.Time - (n-1)*60)\n",
    "        X1 = np.argmin(abs_diff1)\n",
    "        abs_diff2 = np.abs(df_downsample.Time - n*60)\n",
    "        X2 = np.argmin(abs_diff2)\n",
    "        data1 = dff_f_mean_from_each_dff[:switch1][X1:X2+1]\n",
    "        data2 = velocity_f_positive[:switch1][X1:X2+1]\n",
    "        # Detrend the data\n",
    "        detrended_data1 = detrend(data1)\n",
    "        detrended_data2 = detrend(data2)\n",
    "        # Calculate cross-correlation\n",
    "        cross_corr = crosscorrelation(detrended_data1, detrended_data2, 15) #15 frames~ 1sec lag\n",
    "        # Normalize the cross-correlation to range from -1.0 to 1.0\n",
    "        normalized_corr = cross_corr / np.sqrt(np.sum(detrended_data1 ** 2) * np.sum(detrended_data2 ** 2))\n",
    "        # Find the maximum correlation coefficient\n",
    "        max_corr_coefficient = np.max(normalized_corr)\n",
    "        xcorr_average_minute_familiar.append(max_corr_coefficient) \n",
    "\n",
    "print(xcorr_average_minute_familiar, len(xcorr_average_minute_familiar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min_scale_correlation to speed in env2\n",
    "xcorr_average_minute_novel = []\n",
    "\n",
    "for n in range(1,20+1):\n",
    "    if n == 1:\n",
    "        # Compute the absolute difference between the 'Time' column and 1\n",
    "        abs_diff = np.abs(df_downsample.Time - n*60)\n",
    "        # Find the index of the minimum value in the absolute difference series\n",
    "        X = np.argmin(abs_diff)\n",
    "        data1 = dff_f_mean_from_each_dff[switch1:switch2][:X+1]\n",
    "        data2 = velocity_f_positive[switch1:switch2][:X+1]\n",
    "        # Detrend the data\n",
    "        detrended_data1 = detrend(data1)\n",
    "        detrended_data2 = detrend(data2)\n",
    "        # Calculate cross-correlation\n",
    "        cross_corr = crosscorrelation(detrended_data1, detrended_data2, 15) #15 frames~ 1sec lag\n",
    "        # Normalize the cross-correlation to range from -1.0 to 1.0\n",
    "        normalized_corr = cross_corr / np.sqrt(np.sum(detrended_data1 ** 2) * np.sum(detrended_data2 ** 2))\n",
    "        # Find the maximum correlation coefficient\n",
    "        max_corr_coefficient = np.max(normalized_corr)\n",
    "        xcorr_average_minute_novel.append(max_corr_coefficient)\n",
    "    else:\n",
    "        abs_diff1 = np.abs(df_downsample.Time - (n-1)*60)\n",
    "        X1 = np.argmin(abs_diff1)\n",
    "        abs_diff2 = np.abs(df_downsample.Time - n*60)\n",
    "        X2 = np.argmin(abs_diff2)\n",
    "        data1 = dff_f_mean_from_each_dff[switch1:switch2][X1:X2+1]\n",
    "        data2 = velocity_f_positive[switch1:switch2][X1:X2+1]\n",
    "        # Detrend the data\n",
    "        detrended_data1 = detrend(data1)\n",
    "        detrended_data2 = detrend(data2)\n",
    "        # Calculate cross-correlation\n",
    "        cross_corr = crosscorrelation(detrended_data1, detrended_data2, 15) #15 frames~ 1sec lag\n",
    "        # Normalize the cross-correlation to range from -1.0 to 1.0\n",
    "        normalized_corr = cross_corr / np.sqrt(np.sum(detrended_data1 ** 2) * np.sum(detrended_data2 ** 2))\n",
    "        # Find the maximum correlation coefficient\n",
    "        max_corr_coefficient = np.max(normalized_corr)\n",
    "        xcorr_average_minute_novel.append(max_corr_coefficient)    \n",
    "\n",
    "print(xcorr_average_minute_novel, len(xcorr_average_minute_novel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min_scale_correlation to speed in returned env1\n",
    "xcorr_average_minute_Rfamiliar = []\n",
    "\n",
    "for n in range(1,10+1):\n",
    "    if n == 1:\n",
    "        # Compute the absolute difference between the 'Time' column and 1\n",
    "        abs_diff = np.abs(df_downsample.Time - n*60)\n",
    "        # Find the index of the minimum value in the absolute difference series\n",
    "        X = np.argmin(abs_diff)\n",
    "        data1 = dff_f_mean_from_each_dff[switch2:][:X+1]\n",
    "        data2 = velocity_f_positive[switch2:][:X+1]\n",
    "        # Detrend the data\n",
    "        detrended_data1 = detrend(data1)\n",
    "        detrended_data2 = detrend(data2)\n",
    "        # Calculate cross-correlation\n",
    "        cross_corr = crosscorrelation(detrended_data1, detrended_data2, 15) #15 frames~ 1sec lag\n",
    "        # Normalize the cross-correlation to range from -1.0 to 1.0\n",
    "        normalized_corr = cross_corr / np.sqrt(np.sum(detrended_data1 ** 2) * np.sum(detrended_data2 ** 2))\n",
    "        # Find the maximum correlation coefficient\n",
    "        max_corr_coefficient = np.max(normalized_corr)\n",
    "        xcorr_average_minute_Rfamiliar.append(max_corr_coefficient) \n",
    "    else:\n",
    "        abs_diff1 = np.abs(df_downsample.Time - (n-1)*60)\n",
    "        X1 = np.argmin(abs_diff1)\n",
    "        abs_diff2 = np.abs(df_downsample.Time - n*60)\n",
    "        X2 = np.argmin(abs_diff2)\n",
    "        data1 = dff_f_mean_from_each_dff[switch2:][X1:X2+1]\n",
    "        data2 = velocity_f_positive[switch2:][X1:X2+1]\n",
    "        # Detrend the data\n",
    "        detrended_data1 = detrend(data1)\n",
    "        detrended_data2 = detrend(data2)\n",
    "        # Calculate cross-correlation\n",
    "        cross_corr = crosscorrelation(detrended_data1, detrended_data2, 15) #15 frames~ 1sec lag\n",
    "        # Normalize the cross-correlation to range from -1.0 to 1.0\n",
    "        normalized_corr = cross_corr / np.sqrt(np.sum(detrended_data1 ** 2) * np.sum(detrended_data2 ** 2))\n",
    "        # Find the maximum correlation coefficient\n",
    "        max_corr_coefficient = np.max(normalized_corr)\n",
    "        xcorr_average_minute_Rfamiliar.append(max_corr_coefficient) \n",
    "\n",
    "print(xcorr_average_minute_Rfamiliar, len(xcorr_average_minute_Rfamiliar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('xcorr_minute_familiar_240804_C20',np.array(xcorr_average_minute_familiar))\n",
    "np.save('xcorr_minute_novel_240804_C20',np.array(xcorr_average_minute_novel))\n",
    "np.save('xcorr_minute_Rfamiliar_240804_C20',np.array(xcorr_average_minute_Rfamiliar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overall_Cross correlation_between 3env\n",
    "from matplotlib import mlab\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "xcor_value0 = plt.xcorr(pd.DataFrame(dff_f_mean_from_each_dff)[0][:switch1], \n",
    "                       velocity_f_positive[:switch1],\n",
    "                       detrend=mlab.detrend_linear, \n",
    "                       maxlags=300,\n",
    "                       color='blue',\n",
    "                       alpha=0.1\n",
    "                       )\n",
    "\n",
    "xcor_value2 = plt.xcorr(pd.DataFrame(dff_f_mean_from_each_dff)[0][switch1+1:switch2-1], \n",
    "                       velocity_f_positive[switch1+1:switch2-1],\n",
    "                       detrend=mlab.detrend_linear, \n",
    "                       maxlags=300,\n",
    "                       color='green',\n",
    "                       alpha=0.1)\n",
    "\n",
    "xcor_value5 = plt.xcorr(pd.DataFrame(dff_f_mean_from_each_dff)[0][switch2+1:], \n",
    "                       velocity_f_positive[switch2+1:],\n",
    "                       detrend=mlab.detrend_linear, \n",
    "                       maxlags=300,\n",
    "                       color='midnightblue',\n",
    "                       alpha=0.1\n",
    "                       )\n",
    "\n",
    "\n",
    "custom_xtick_positions = [-309.8,0,309.8]\n",
    "custom_xtick_labels = ['-20','0','20']\n",
    "plt.xticks(custom_xtick_positions,custom_xtick_labels)\n",
    "plt.xlabel(\"sec\")\n",
    "plt.suptitle(\"240804_C20_dff_crosscorrelation\",y=1.0, fontsize='xx-large')\n",
    "plt.ylim(-0.7,1)\n",
    "\n",
    "# Create custom legend handles and labels\n",
    "legend_handles = [Line2D([0], [0], color='blue', alpha=0.75,label='env1'),\n",
    "                  Line2D([0], [0], color='green', alpha=0.75,label='env2'),\n",
    "                  Line2D([0], [0], color='midnightblue', alpha=0.75,label='returned_env1')]\n",
    "\n",
    "# Add the legend with custom handles and labels\n",
    "#plt.legend(handles=legend_handles)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Trace with velocity&Lick\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=[10,4])\n",
    "\n",
    "ax1.plot(df_downsample.Velocity[2000:5000], \n",
    "        \n",
    "         color='tab:blue', linewidth=0.75)\n",
    "\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(pd.DataFrame(dff_f_mean_from_each_dff)[2000:5000], \n",
    "          color='orange',\n",
    "        linewidth=2)\n",
    "ax2.plot(dfl_downsample.Lick[2000:5000], \n",
    "        \n",
    "         color='magenta', linewidth=2)\n",
    "plt.suptitle(\"240804_C20_2000-5000_mean_velocity\",y=0.95, fontsize='xx-large')\n",
    "ax1.axvspan(2000,5000, facecolor='lightblue', alpha=0.4)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Trace with velocity&Reward\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=[10,4])\n",
    "\n",
    "ax1.plot(df_downsample.Velocity[2000:5000], \n",
    "        \n",
    "         color='tab:blue', linewidth=0.75)\n",
    "\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(pd.DataFrame(dff_f_mean_from_each_dff)[2000:5000], \n",
    "          color='orange',\n",
    "        linewidth=2)\n",
    "ax2.plot(dfl_downsample.Lick[2000:5000],         \n",
    "         color='magenta', linewidth=2)\n",
    "ax2.plot(dfl_downsample.Reward[2000:5000],         \n",
    "         color='green', linewidth=2)\n",
    "plt.suptitle(\"240804_C20_2000-5000_mean_velocity\",y=0.95, fontsize='xx-large')\n",
    "ax1.axvspan(2000,5000, facecolor='lightblue', alpha=0.4)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
