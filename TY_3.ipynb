{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "151cf35d",
   "metadata": {},
   "source": [
    "# Analysis_field size_MEC_soma_VR_linear switch task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ec0527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import skimage as ski\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa676c3",
   "metadata": {},
   "source": [
    "# Prepare behravior dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a140530",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scan1=pd.read_csv(r'D:\\2P_DATA\\Alex_data\\P15\\11_10_20\\suite2p\\plane0\\Scan\\Scan_1.csv')\n",
    "df_scan1=df_scan1.drop(range(0,1)).astype(float)\n",
    "df_scan1[df_scan1['Channel B'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c574b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scan5=pd.read_csv(r'D:\\2P_DATA\\Alex_data\\P15\\11_10_20\\suite2p\\plane0\\Scan\\Scan_5.csv')\n",
    "df_scan5=df_scan5.drop(range(0,1)).astype(float)\n",
    "df_scan5[df_scan5['Channel B'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad92298b",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_cell=11071\n",
    "last_cell=399639"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2582093",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scan\n",
    "path1=r'D:\\2P_DATA\\Alex_data\\P15\\11_10_20\\suite2p\\plane0\\Scan\\Scan_1.csv'\n",
    "path2=r'D:\\2P_DATA\\Alex_data\\P15\\11_10_20\\suite2p\\plane0\\Scan\\Scan_2.csv'\n",
    "path3=r'D:\\2P_DATA\\Alex_data\\P15\\11_10_20\\suite2p\\plane0\\Scan\\Scan_3.csv'\n",
    "path4=r'D:\\2P_DATA\\Alex_data\\P15\\11_10_20\\suite2p\\plane0\\Scan\\Scan_4.csv'\n",
    "path5=r'D:\\2P_DATA\\Alex_data\\P15\\11_10_20\\suite2p\\plane0\\Scan\\Scan_5.csv'\n",
    "\n",
    "df1 = pd.read_csv(path1,low_memory=False)\n",
    "\n",
    "df1=df1.drop(range(0,first_cell)).astype(float)#input the range to extract the duration of 2P scanning #(first cell #) - 4(excel matter)-32\n",
    "df1[\"Time\"] = df1[\"Time\"] - df1[\"Time\"][first_cell] #input the start point to set the time as \"0\"\n",
    "df1=df1.reset_index().drop(columns=\"index\")\n",
    "\n",
    "df2 = pd.read_csv(path2,low_memory=False)\n",
    "df2=df2.drop(0).astype(float)\n",
    "df2[\"Time\"] = df2[\"Time\"] + df1['Time'].iloc[-1] + (485.814958-0)/(874456-0)\n",
    "df2=df2.reset_index().drop(columns=\"index\")\n",
    "\n",
    "df3 = pd.read_csv(path3,low_memory=False)\n",
    "df3=df3.drop(0).astype(float)\n",
    "df3[\"Time\"] = df3[\"Time\"] + df2['Time'].iloc[-1] + (485.814958-0)/(874456-0)\n",
    "df3=df3.reset_index().drop(columns=\"index\")\n",
    "\n",
    "df4 = pd.read_csv(path4,low_memory=False)\n",
    "df4=df4.drop(0).astype(float)\n",
    "df4[\"Time\"] = df4[\"Time\"] + df3['Time'].iloc[-1] + (485.814958-0)/(874456-0)\n",
    "df4=df4.reset_index().drop(columns=\"index\")\n",
    "\n",
    "df5 = pd.read_csv(path5, low_memory=False)\n",
    "df5 = df5.drop(0).astype(float)\n",
    "\n",
    "df5=df5[:last_cell]\n",
    "df5[\"Time\"] = df5[\"Time\"] + df4['Time'].iloc[-1] + (485.814958-0)/(874456-0) # + time of last cell in df1 + time gap between each cell\n",
    "df5=df5.reset_index().drop(columns=\"index\")\n",
    "\n",
    "df1_5=pd.concat([df1,df2,df3,df4,df5], axis=0, sort=False)\n",
    "df1_5=df1_5.reset_index().drop(columns=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35867d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6896bf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_scan1 is your DataFrame\n",
    "df1_5_scan = df1_5[df1_5['Channel B'] > 1]['Time']\n",
    "\n",
    "# Initialize an empty list to hold the pairs\n",
    "time_pairs = []\n",
    "\n",
    "# Iterate through the Time series\n",
    "for i in range(1, len(df1_5_scan)):\n",
    "    if df1_5_scan.iloc[i] - df1_5_scan.iloc[i-1] > 0.5:\n",
    "        time_pairs.append([df1_5_scan.iloc[i-1], df1_5_scan.iloc[i]])\n",
    "\n",
    "# Print the result\n",
    "print(time_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f01bf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df1_5 is your DataFrame\n",
    "df1_5_scan = df1_5[df1_5['Channel B'] > 1]['Time']\n",
    "\n",
    "# Initialize an empty list to hold the indices\n",
    "index_pairs = []\n",
    "\n",
    "# Iterate through the Time series\n",
    "for i in range(1, len(df1_5_scan)):\n",
    "    if df1_5_scan.iloc[i] - df1_5_scan.iloc[i-1] > 0.5:\n",
    "        # Get the original indices from df1_5\n",
    "        index_prev = df1_5_scan.index[i-1]\n",
    "        index_curr = df1_5_scan.index[i]\n",
    "        index_pairs.append([index_prev, index_curr])\n",
    "\n",
    "# Print the result\n",
    "print(index_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9241742",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(index_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf19a838",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirming slice number\n",
    "66022/22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91ef850",
   "metadata": {},
   "outputs": [],
   "source": [
    "tail=int(1000004/5178/2) #average index after the final scan detected\n",
    "tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deffb8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to hold the DataFrames\n",
    "dataframes = {}\n",
    "\n",
    "for i in range(0,len(index_pairs)+1):\n",
    "    if i == 0:        \n",
    "        dataframes[f'df{i+1}'] = df1_5.iloc[0:(index_pairs[i][0]+tail)]\n",
    "    elif i>0 and i<len(index_pairs):\n",
    "        dataframes[f'df{i+1}'] = df1_5.iloc[index_pairs[i-1][1]:(index_pairs[i][0]+tail)]\n",
    "    elif i == len(index_pairs):\n",
    "        dataframes[f'df{i+1}'] = df1_5.iloc[index_pairs[i-1][1]:len(df1_5)]\n",
    "\n",
    "dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8379dd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Velocity\n",
    "path1=r'D:\\2P_DATA\\Alex_data\\P15\\11_10_20\\suite2p\\plane0\\Velocity\\Velocity_1.csv'\n",
    "path2=r'D:\\2P_DATA\\Alex_data\\P15\\11_10_20\\suite2p\\plane0\\Velocity\\Velocity_2.csv'\n",
    "path3=r'D:\\2P_DATA\\Alex_data\\P15\\11_10_20\\suite2p\\plane0\\Velocity\\Velocity_3.csv'\n",
    "path4=r'D:\\2P_DATA\\Alex_data\\P15\\11_10_20\\suite2p\\plane0\\Velocity\\Velocity_4.csv'\n",
    "path5=r'D:\\2P_DATA\\Alex_data\\P15\\11_10_20\\suite2p\\plane0\\Velocity\\Velocity_5.csv'\n",
    "\n",
    "df1 = pd.read_csv(path1,low_memory=False)\n",
    "\n",
    "df1=df1.drop(range(0,first_cell)).astype(float)#input the range to extract the duration of 2P scanning #(first cell #) - 4(excel matter)-32\n",
    "df1[\"Time\"] = df1[\"Time\"] - df1[\"Time\"][first_cell] #input the start point to set the time as \"0\"\n",
    "df1=df1.reset_index().drop(columns=\"index\")\n",
    "\n",
    "df2 = pd.read_csv(path2,low_memory=False)\n",
    "df2=df2.drop(0).astype(float)\n",
    "df2[\"Time\"] = df2[\"Time\"] + df1['Time'].iloc[-1] + (485.814958-0)/(874456-0)\n",
    "df2=df2.reset_index().drop(columns=\"index\")\n",
    "\n",
    "df3 = pd.read_csv(path3,low_memory=False)\n",
    "df3=df3.drop(0).astype(float)\n",
    "df3[\"Time\"] = df3[\"Time\"] + df2['Time'].iloc[-1] + (485.814958-0)/(874456-0)\n",
    "df3=df3.reset_index().drop(columns=\"index\")\n",
    "\n",
    "df4 = pd.read_csv(path4,low_memory=False)\n",
    "df4=df4.drop(0).astype(float)\n",
    "df4[\"Time\"] = df4[\"Time\"] + df3['Time'].iloc[-1] + (485.814958-0)/(874456-0)\n",
    "df4=df4.reset_index().drop(columns=\"index\")\n",
    "\n",
    "df5 = pd.read_csv(path5, low_memory=False)\n",
    "df5 = df5.drop(0).astype(float)\n",
    "\n",
    "df5=df5[:last_cell]\n",
    "df5[\"Time\"] = df5[\"Time\"] + df4['Time'].iloc[-1] + (485.814958-0)/(874456-0) # + time of last cell in df1 + time gap between each cell\n",
    "df5=df5.reset_index().drop(columns=\"index\")\n",
    "\n",
    "df1_5=pd.concat([df1,df2,df3,df4,df5], axis=0, sort=False)\n",
    "df1_5=df1_5.reset_index().drop(columns=\"index\")\n",
    "df1_5.columns=(\"Time\",\"Velocity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13833ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99047f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Position\n",
    "path1=r'D:\\2P_DATA\\Alex_data\\P15\\11_10_20\\suite2p\\plane0\\Position\\Position_1.csv'\n",
    "path2=r'D:\\2P_DATA\\Alex_data\\P15\\11_10_20\\suite2p\\plane0\\Position\\Position_2.csv'\n",
    "path3=r'D:\\2P_DATA\\Alex_data\\P15\\11_10_20\\suite2p\\plane0\\Position\\Position_3.csv'\n",
    "path4=r'D:\\2P_DATA\\Alex_data\\P15\\11_10_20\\suite2p\\plane0\\Position\\Position_4.csv'\n",
    "path5=r'D:\\2P_DATA\\Alex_data\\P15\\11_10_20\\suite2p\\plane0\\Position\\Position_5.csv'\n",
    "\n",
    "df1 = pd.read_csv(path1,low_memory=False)\n",
    "\n",
    "df1=df1.drop(range(0,first_cell)).astype(float)#input the range to extract the duration of 2P scanning #(first cell #) - 4(excel matter)-32\n",
    "df1[\"Time\"] = df1[\"Time\"] - df1[\"Time\"][first_cell] #input the start point to set the time as \"0\"\n",
    "df1=df1.reset_index().drop(columns=\"index\")\n",
    "\n",
    "df2 = pd.read_csv(path2,low_memory=False)\n",
    "df2=df2.drop(0).astype(float)\n",
    "df2[\"Time\"] = df2[\"Time\"] + df1['Time'].iloc[-1] + (485.814958-0)/(874456-0)\n",
    "df2=df2.reset_index().drop(columns=\"index\")\n",
    "\n",
    "df3 = pd.read_csv(path3,low_memory=False)\n",
    "df3=df3.drop(0).astype(float)\n",
    "df3[\"Time\"] = df3[\"Time\"] + df2['Time'].iloc[-1] + (485.814958-0)/(874456-0)\n",
    "df3=df3.reset_index().drop(columns=\"index\")\n",
    "\n",
    "df4 = pd.read_csv(path4,low_memory=False)\n",
    "df4=df4.drop(0).astype(float)\n",
    "df4[\"Time\"] = df4[\"Time\"] + df3['Time'].iloc[-1] + (485.814958-0)/(874456-0)\n",
    "df4=df4.reset_index().drop(columns=\"index\")\n",
    "\n",
    "df5 = pd.read_csv(path5, low_memory=False)\n",
    "df5 = df5.drop(0).astype(float)\n",
    "\n",
    "df5=df5[:last_cell]\n",
    "df5[\"Time\"] = df5[\"Time\"] + df4['Time'].iloc[-1] + (485.814958-0)/(874456-0) # + time of last cell in df1 + time gap between each cell\n",
    "df5=df5.reset_index().drop(columns=\"index\")\n",
    "\n",
    "dfpe1_5=pd.concat([df1,df2,df3,df4,df5], axis=0, sort=False)\n",
    "dfpe1_5=dfpe1_5.reset_index().drop(columns=\"index\")\n",
    "dfpe1_5.columns=(\"Time\",\"Position\",\"Environment\")\n",
    "dfpe1_5.Position=3*(dfpe1_5.Position-dfpe1_5.Position.min())/((dfpe1_5.Position-dfpe1_5.Position.min()).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a02c415",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpe1_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa22cf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvpe=pd.concat([df1_5['Time'],df1_5['Velocity'],dfpe1_5['Position'],dfpe1_5['Environment']],axis=1,sort=False)\n",
    "dfvpe.columns=(\"Time\",\"Velocity\",\"Position\",\"Environment\")\n",
    "dfvpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0069b948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to hold the DataFrames\n",
    "dataframes = {}\n",
    "\n",
    "for i in range(0,len(index_pairs)+1):\n",
    "    if i == 0:        \n",
    "        dataframes[f'df{i+1}'] = dfvpe.iloc[0:(index_pairs[i][0]+tail)]\n",
    "    elif i>0 and i<len(index_pairs):\n",
    "        dataframes[f'df{i+1}'] = dfvpe.iloc[index_pairs[i-1][1]:(index_pairs[i][0]+tail)]\n",
    "    elif i == len(index_pairs):\n",
    "        dataframes[f'df{i+1}'] = dfvpe.iloc[index_pairs[i-1][1]:len(dfvpe)]\n",
    "\n",
    "dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba5ba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_downsample = pd.DataFrame()\n",
    "n_slices=3001\n",
    "n=np.array(range(0, n_slices, 1)) #range(0, number of 2P slices)\n",
    "#Downsample\n",
    "for i in range(0,len(index_pairs)+1):\n",
    "    df=dataframes[f'df{i+1}'].reset_index().drop(columns=\"index\")\n",
    "    for u in range(0,3001):  \n",
    "        df_each_cell = round(u*(df.iloc[[-1]].index[0]/(n_slices-1))) # last cell of detection / # of frames - 1\n",
    "        df_each = pd.DataFrame(df.iloc[df_each_cell]).T\n",
    "        df_downsample = pd.concat([df_downsample,df_each], axis=0, sort=False) \n",
    "\n",
    "df_downsample=df_downsample.reset_index().drop(columns=\"index\")        \n",
    "df_downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce365a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_downsample.to_csv('df_downsample.csv',index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf17e01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_downsample=pd.read_csv('df_downsample.csv')\n",
    "df_downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52f266d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_downsample.Position=df_downsample.Position*100\n",
    "df_downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782d4531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the cell swicthing environment\n",
    "n = np.array(range(0,len(df_downsample)-1,1))\n",
    "for u in n: \n",
    "    if abs(df_downsample.Environment[u+1]-df_downsample.Environment[u]) > 1.5:\n",
    "        print(u+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac23064",
   "metadata": {},
   "outputs": [],
   "source": [
    "switch1=19611\n",
    "switch2=46766"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c0fd7b",
   "metadata": {},
   "source": [
    "## Fluorescence data and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b504a894",
   "metadata": {},
   "outputs": [],
   "source": [
    "F=np.load('F.npy')\n",
    "iscell=np.load('iscell.npy',allow_pickle=True)[:,0]\n",
    "stat=np.load('stat.npy',allow_pickle=True)\n",
    "\n",
    "F.shape, iscell.shape, stat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e26f217",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the cell ids\n",
    "ncells=len(stat)\n",
    "cell_ids = np.arange(ncells)\n",
    "\n",
    "#detect trace data of cells\n",
    "condition = np.mod(iscell, 2)==1\n",
    "cells=np.extract(condition,cell_ids)\n",
    "F_cell=F[cells,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b11be6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "condition.shape, cells.shape, F_cell.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e442b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the dff array with the same shape as F\n",
    "dff = np.zeros_like(F_cell)\n",
    "\n",
    "# Loop through each element in F\n",
    "for i in range(len(F_cell)):\n",
    "    for n in range(len(F_cell[0])):\n",
    "        # Determine the start and end of the window\n",
    "        start = max(0, n - 1500)\n",
    "        end = min(len(F_cell[0]), n + 1500)\n",
    "        \n",
    "        # Extract the window\n",
    "        window = F_cell[i][start:end]\n",
    "        \n",
    "        # Calculate the 8th percentile for F0\n",
    "        F0 = np.percentile(window, 8)\n",
    "        \n",
    "        # Calculate dff\n",
    "        dff[i, n] = 100 * (F_cell[i, n] - F0) / F0\n",
    "\n",
    "# Check the shape of the resulting dff array\n",
    "print(dff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412b3021",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('dff_P15.npy',dff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb92d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff=np.load('dff_P15.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ace6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detect transients\n",
    "\n",
    "from scipy.ndimage import label\n",
    "\n",
    "# Initialize dff_transient with zeros\n",
    "dff_transient = np.zeros_like(F_cell)\n",
    "\n",
    "# Calculate mean and standard deviation for each row in advance\n",
    "means = np.mean(dff, axis=1)\n",
    "stds = np.std(dff, axis=1)\n",
    "\n",
    "# Calculate the initial threshold (mean + 2 * std) for each row\n",
    "initial_thresholds = means + 2 * stds\n",
    "\n",
    "# Initialize lists to store the new means and stds\n",
    "new_means = []\n",
    "new_stds = []\n",
    "\n",
    "# Find the longest sequence of values less than the initial threshold for each row\n",
    "for i in range(dff.shape[0]):\n",
    "    below_threshold = dff[i, :] < initial_thresholds[i]\n",
    "    labeled_array, num_features = label(below_threshold)\n",
    "    \n",
    "    # Find the longest sequence\n",
    "    max_length = 0\n",
    "    max_seq = None\n",
    "    for feature_num in range(1, num_features + 1):\n",
    "        feature_indices = np.where(labeled_array == feature_num)[0]\n",
    "        if len(feature_indices) > max_length:\n",
    "            max_length = len(feature_indices)\n",
    "            max_seq = feature_indices\n",
    "\n",
    "    if max_seq is not None:\n",
    "        # Recalculate mean and std based on the longest sequence\n",
    "        new_mean = np.mean(dff[i, max_seq])\n",
    "        new_std = np.std(dff[i, max_seq])\n",
    "    else:\n",
    "        new_mean = np.mean(dff[i, :])\n",
    "        new_std = np.std(dff[i, :])\n",
    "    \n",
    "    new_means.append(new_mean)\n",
    "    new_stds.append(new_std)\n",
    "\n",
    "# Convert lists to arrays\n",
    "new_means = np.array(new_means)\n",
    "new_stds = np.array(new_stds)\n",
    "\n",
    "# Calculate the new thresholds (mean + 2 * std) for each row\n",
    "new_thresholds = new_means + 2 * new_stds\n",
    "\n",
    "# Use broadcasting to compare and assign values\n",
    "dff_transient = np.where(dff > new_thresholds[:, None], dff, 0)\n",
    "\n",
    "# Check the result\n",
    "print(dff_transient)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d68cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criteria 2: get the positive data last over 30 points\n",
    "\n",
    "from scipy.ndimage import label\n",
    "\n",
    "# Additional condition: non-zero values must last for at least 30 consecutive points\n",
    "min_length = 10\n",
    "\n",
    "for i in range(dff_transient.shape[0]):\n",
    "    # Label contiguous non-zero regions\n",
    "    labeled_array, num_features = label(dff_transient[i, :] > 0)\n",
    "    \n",
    "    # Iterate over each feature to check its length\n",
    "    for feature_num in range(1, num_features + 1):\n",
    "        feature_indices = np.where(labeled_array == feature_num)[0]\n",
    "        if len(feature_indices) < min_length:\n",
    "            dff_transient[i, feature_indices] = 0\n",
    "\n",
    "# Check the result\n",
    "print(dff_transient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb4c0b9",
   "metadata": {},
   "source": [
    "## Inspection by plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9087e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=[10,4]) \n",
    "    \n",
    "ax1.plot(dff[0], label=\"Mean Trace\",  color='#0344DF')\n",
    "\n",
    "plt.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    \n",
    "plt.legend(bbox_to_anchor=(0.93, 1.1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2d3e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=[10,4]) \n",
    "    \n",
    "ax1.plot(dff_transient[0], label=\"Mean Trace\",  color='#0344DF')\n",
    "\n",
    "plt.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    \n",
    "plt.legend(bbox_to_anchor=(0.93, 1.1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127721b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=[10,4]) \n",
    "    \n",
    "ax1.plot(dff_transient[0], label=\"Mean Trace\",  color='#0344DF')\n",
    "\n",
    "plt.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    \n",
    "plt.legend(bbox_to_anchor=(0.93, 1.1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916d8ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=[10,4]) \n",
    "    \n",
    "ax1.plot(dff[0][12000:14000], label=\"Mean Trace\",  color='#0344DF')\n",
    "\n",
    "plt.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    \n",
    "plt.legend(bbox_to_anchor=(0.93, 1.1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730954bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=[10,4]) \n",
    "    \n",
    "ax1.plot(dff_transient[0][12000:14000], label=\"Mean Trace\",  color='#0344DF')\n",
    "\n",
    "plt.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    \n",
    "plt.legend(bbox_to_anchor=(0.93, 1.1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41b9855",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_downsample_familiar=df_downsample[:switch1]\n",
    "df_downsample_novel=df_downsample[switch1:switch2]\n",
    "df_downsample_Rfamiliar=df_downsample[switch2:]\n",
    "dff_familiar=dff_transient[:,:switch1]\n",
    "dff_novel=dff_transient[:,switch1:switch2]\n",
    "dff_Rfamiliar=dff_transient[:,switch2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7c3c54",
   "metadata": {},
   "source": [
    "## Calculation for spatial field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c1e60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from scipy.ndimage import gaussian_filter1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481f44fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting\n",
    "num_Spatial_Bins=100\n",
    "trackLenth = 300 # cm\n",
    "frame_rate = 1/30.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9c7d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper funtion\n",
    "def bwlabel(data):\n",
    "    count=0\n",
    "    label= np.zeros((len(data)))\n",
    "    if data[0]!=0:\n",
    "        label[0]=1\n",
    "\n",
    "    for i in range(1,len(data)):\n",
    "        if (data[i]!=0) & (data[i-1]!=0):\n",
    "            label[i]=count\n",
    "        elif (data[i]!=0) & (data[i-1]==0):\n",
    "            count=count+1\n",
    "            label[i]=count\n",
    "\n",
    "    return label\n",
    "\n",
    "def double_thresh(data, lower_thresh,upper_thresh):\n",
    "    state = np.zeros((len(data)))\n",
    "    if data[0]<lower_thresh:\n",
    "        state[0]=0\n",
    "    else:\n",
    "        state[0]=1\n",
    "    \n",
    "    for i in range(1,len(data)):\n",
    "        state[i]=state[i-1]\n",
    "        if state[i-1]==0:\n",
    "            if data[i]>upper_thresh:\n",
    "                state[i]=1\n",
    "        else:\n",
    "            if data[i]<lower_thresh:\n",
    "                state[i]=0\n",
    "    \n",
    "    return state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1028eca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_running(speed,lower_thresh,upper_thresh,sit_thresh,run_thresh):\n",
    "    # smooth with gaussion filter\n",
    "    speed = gaussian_filter1d(np.array(speed), sigma=12, axis=0, mode='wrap')\n",
    "    # double thereshold\n",
    "    run_state = double_thresh(speed ,lower_thresh,upper_thresh)\n",
    "    # if any period of imoobility is smaller than sit_thresh seconds, include these data\n",
    "    run_state_invert = np.where(run_state==0,1,0)\n",
    "    run_state_invert2 = bwlabel(run_state_invert)\n",
    "    for i in range(int(np.max(run_state_invert2))):\n",
    "        if len(run_state_invert2[run_state_invert2==i])<60*sit_thresh:\n",
    "            run_state=np.where(run_state_invert2==i,1,run_state)\n",
    "    # if any period of running is smaller than run_thresh seconds, do not include these data\n",
    "    run_state2 = bwlabel(run_state)\n",
    "    for i in range(int(np.max(run_state2))):\n",
    "        if len(run_state2[run_state2==i])<60*run_thresh:\n",
    "            run_state=np.where(run_state2==i,0,run_state)\n",
    "    running_index = np.squeeze(np.array([ind for (ind, val) in np.ndenumerate(run_state) if val==1 ] )) \n",
    "    \n",
    "    return running_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cd8dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_spatial_FR_map(Position,dFF,num_bins,frame_rate,trackLenth ):\n",
    "  # calculate lap num at every time point\n",
    "  lap=1\n",
    "  lap_num = np.zeros(len(Position))\n",
    "  for i in range(len(Position)-1):\n",
    "      lap_num[i] = lap\n",
    "      if abs(Position[i]-Position[i+1])>50 :\n",
    "        lap=lap+1\n",
    "  lap_num[-1]= lap\n",
    "  num_of_laps = int(np.max(lap_num))\n",
    "  # calculate spatial bin number at every time point\n",
    "  binsize = trackLenth /num_bins\n",
    "  bin_edges = np.arange(0, trackLenth+binsize, binsize)\n",
    "  spatial_bin_num = np.digitize(Position, bin_edges,right=True)\n",
    "  # initiate\n",
    "  spatial_FR_map_session = np.zeros(num_bins,dtype=float)\n",
    "  spatial_FR_map_lap = np.zeros((num_of_laps ,num_bins),dtype=float)\n",
    "  time_spent = np.zeros((num_of_laps ,num_bins),dtype=float)\n",
    "  # find the data point that belongs to a specific bin\n",
    "  for bins in range(num_bins): \n",
    "      temp_ind = np.where(spatial_bin_num==bins+1)[0]\n",
    "      if temp_ind.size == 0:\n",
    "            spatial_FR_map_session[bins] = np.nan\n",
    "      else:\n",
    "            spatial_FR_map_session[bins] = np.nansum(dFF[temp_ind])/(len(temp_ind)*frame_rate)\n",
    "            \n",
    "      for laps in range(num_of_laps):\n",
    "          temp_ind2 = np.where((lap_num == laps+1) & (spatial_bin_num==bins+1))[0]\n",
    "          if temp_ind2.size == 0:\n",
    "            spatial_FR_map_lap[laps,bins] = np.nan\n",
    "            time_spent[laps,bins] = np.nan\n",
    "          else:\n",
    "            time_spent[laps,bins] = len(temp_ind2)*frame_rate\n",
    "            spatial_FR_map_lap[laps,bins] = np.nansum(dFF[temp_ind2])/time_spent[laps,bins] \n",
    "                  \n",
    "  return spatial_FR_map_session,spatial_FR_map_lap,time_spent,lap_num "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1909f9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate spatial information using spatial occupancy\n",
    "def calculate_spatial_info(spatial_FR_map_session,spatial_occupancy):\n",
    "# ref: Skaggs et al.,1993\n",
    "   session_mean_FR = np.nansum(spatial_FR_map_session*spatial_occupancy)\n",
    "   norm_spatial_FR_map = spatial_FR_map_session/session_mean_FR\n",
    "   spatial_info = np.nansum(spatial_FR_map_session*np.log2(norm_spatial_FR_map)*spatial_occupancy)\n",
    "   return spatial_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a01b88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_spike_count_by_lap(dFF_matrix,time_spent,lap_num,shuffle_times,spatial_occupancy):\n",
    "  num_of_neuron = len(dFF_matrix)\n",
    "  num_of_laps = time_spent.shape[0]\n",
    "  num_of_bin = time_spent.shape[1]\n",
    "   # initiate\n",
    "  spatial_info_shuffled = np.zeros((num_of_neuron,shuffle_times),dtype=float)\n",
    "  map_shuffled = np.zeros((shuffle_times,num_of_neuron,num_of_bin),dtype=float)\n",
    "  # find index for every lap\n",
    "  lap_temp_ind = [[]]*num_of_laps\n",
    "  for laps in range(num_of_laps):\n",
    "      lap_temp_ind[laps] = np.where(lap_num == laps+1)[0]\n",
    "  # find spatial bin number at every time point\n",
    "  binsize = trackLenth /num_of_bin \n",
    "  bin_edges = np.arange(0, trackLenth+binsize, binsize)\n",
    "  spatial_bin_num = np.digitize(Position, bin_edges,right=True)\n",
    "\n",
    "  for i in range(shuffle_times):\n",
    "     dFF_shuffled = np.zeros_like(dFF_matrix)\n",
    "     # shuffle dFF in each lap\n",
    "     for laps in range(num_of_laps):\n",
    "       if len(lap_temp_ind[laps]) != 0:\n",
    "         time_shift = np.random.randint(len(lap_temp_ind[laps]))\n",
    "         # go over neurons\n",
    "         for neurons in range(num_of_neuron):\n",
    "           # shuffle the dFF in one lap\n",
    "           dFF_shuffled[neurons,lap_temp_ind[laps]]=np.roll(dFF_matrix[neurons,lap_temp_ind[laps]],time_shift)\n",
    "\n",
    "     # calculate session mean spatial firing rate map for all neurons using shuffled dFF matrix\n",
    "     spatial_FR_map_matrix= np.zeros((num_of_neuron,num_of_bin),dtype=float)\n",
    "     for bins in range(num_of_bin): \n",
    "         temp_ind = np.where(spatial_bin_num==bins+1)[0]\n",
    "         for neurons in range(num_of_neuron):\n",
    "            if temp_ind.size == 0:\n",
    "               spatial_FR_map_matrix[neurons,bins] = np.nan\n",
    "            else:\n",
    "               spatial_FR_map_matrix[neurons,bins] = np.nansum(dFF_shuffled[neurons,temp_ind])/(len(temp_ind)*frame_rate) \n",
    "     map_shuffled[i,:,:] = spatial_FR_map_matrix\n",
    "     \n",
    "     # calculate spatial info for all neurons using shuffled session mean spatial firing rate map\n",
    "     # ref: Skaggs et al.,1993\n",
    "     spatial_info = np.zeros((num_of_neuron,),dtype=float)\n",
    "     for neurons in range(num_of_neuron):\n",
    "         session_mean_FR = np.nansum(spatial_FR_map_matrix[neurons,:]*spatial_occupancy)\n",
    "         norm_spatial_FR_map = spatial_FR_map_matrix[neurons,:]/session_mean_FR\n",
    "         spatial_info[neurons] = np.nansum(spatial_FR_map_matrix[neurons,:]*np.log2(norm_spatial_FR_map)*spatial_occupancy)\n",
    "     spatial_info_shuffled[:,i] = spatial_info\n",
    "     \n",
    "  return spatial_info_shuffled,map_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e32e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import measure  # Ensure correct import for label function\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "def gaussian_filter_segments(data, sigma, axis=-1, mode='wrap'):\n",
    "    def filter_row(row):\n",
    "        nan_indices = np.isnan(row)\n",
    "        segments = []\n",
    "        start = 0\n",
    "\n",
    "        for j in range(len(row)):\n",
    "            if nan_indices[j]:\n",
    "                if start != j:\n",
    "                    segments.append(row[start:j])\n",
    "                segments.append(np.array([np.nan]))\n",
    "                start = j + 1\n",
    "\n",
    "        if start < len(row):\n",
    "            segments.append(row[start:])\n",
    "\n",
    "        filtered_row = np.empty_like(row)\n",
    "        filtered_row[:] = np.nan\n",
    "        filtered_segments = [gaussian_filter1d(seg, sigma, mode=mode) if not np.isnan(seg).all() else seg for seg in segments]\n",
    "\n",
    "        pos = 0\n",
    "        for seg in filtered_segments:\n",
    "            filtered_row[pos:pos+len(seg)] = seg\n",
    "            pos += len(seg)\n",
    "\n",
    "        return filtered_row\n",
    "\n",
    "    if data.ndim == 2:\n",
    "        if axis == 0:\n",
    "            return np.array([filter_row(data[:, i]) for i in range(data.shape[1])]).T\n",
    "        else:\n",
    "            return np.array([filter_row(data[i, :]) for i in range(data.shape[0])])\n",
    "    elif data.ndim == 3:\n",
    "        filtered_data = np.empty_like(data)\n",
    "        for i in range(data.shape[0]):\n",
    "            for j in range(data.shape[1]):\n",
    "                filtered_data[i, j, :] = filter_row(data[i, j, :])\n",
    "        return filtered_data\n",
    "    else:\n",
    "        raise ValueError(\"Data should be 2D or 3D\")\n",
    "\n",
    "def calculat_spatial_field(spatial_FR_map_session, spatial_FR_map_lap,\n",
    "                           map_shuffled, FRthr, shuffle_thr, min_width, valid_lap_num_thr,\n",
    "                           spatial_info, spatial_info_shuffled):\n",
    "    # Initialize\n",
    "    spatial_field1 = np.zeros_like(spatial_FR_map_session, dtype=int)\n",
    "    spatial_field2 = np.zeros_like(spatial_FR_map_session, dtype=int)\n",
    "    spatial_field3 = np.zeros_like(spatial_FR_map_session, dtype=int)\n",
    "\n",
    "    # Smooth\n",
    "    spatial_FR_map_session = gaussian_filter_segments(spatial_FR_map_session, sigma=2, axis=-1, mode='wrap')\n",
    "    map_shuffled = gaussian_filter_segments(map_shuffled, sigma=2, axis=-1, mode='wrap')\n",
    "\n",
    "    for neurons in range(len(spatial_FR_map_session)):\n",
    "        # Condition #1: Spatial FR > threshold of FR in all bins\n",
    "        tc = spatial_FR_map_session[neurons, :]\n",
    "        tc = tc > np.nanpercentile(tc, FRthr)\n",
    "        tc = measure.label(tc)  # Correct usage of label function\n",
    "        for field in range(np.max(tc)):\n",
    "            if np.sum(tc == field + 1) <= min_width:\n",
    "                tc[tc == field + 1] = 0\n",
    "        spatial_field1[neurons, :] = tc > 0  \n",
    "\n",
    "        # Condition #2: Spatial FR > threshold of shuffled map FR\n",
    "        spatial_field2[neurons, :] = spatial_FR_map_session[neurons, :] > np.nanpercentile(map_shuffled[:, neurons, :], shuffle_thr, axis=0)\n",
    "\n",
    "    spatial_field = spatial_field1 * spatial_field2\n",
    "\n",
    "    # Condition #4: Num of laps with spikes inside spatial field\n",
    "    valid_lap_num = np.zeros((len(spatial_FR_map_session), 10))\n",
    "    for neurons in range(len(spatial_FR_map_session)):\n",
    "        tc2 = measure.label(spatial_field[neurons, :])  # Correct usage of label function\n",
    "        for fields in range(np.max(tc2)):\n",
    "            field_ind = [ind for (ind, val) in np.ndenumerate(tc2) if val == fields + 1]\n",
    "            valid_lap_num[neurons, fields] = np.count_nonzero(np.nansum(spatial_FR_map_lap[neurons, :, field_ind], axis=0))\n",
    "            if valid_lap_num[neurons, fields] < valid_lap_num_thr:\n",
    "                tc2[tc2 == fields + 1] = 0\n",
    "        spatial_field3[neurons, :] = tc2 > 0\n",
    "\n",
    "    spatial_field = spatial_field * spatial_field3\n",
    "\n",
    "    # Condition #5: Spatial info\n",
    "    spatial_info_percentile = np.nanpercentile(spatial_info_shuffled, 95, axis=1)\n",
    "    for neurons in range(len(spatial_FR_map_session)):\n",
    "        if spatial_info[neurons] < spatial_info_percentile[neurons]:\n",
    "            spatial_field[neurons, :] = np.zeros_like(spatial_field[neurons, :])\n",
    "\n",
    "    return spatial_field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7883d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from skimage import measure\n",
    "\n",
    "def calculate_spatial_field(spatial_FR_map_session, spatial_FR_map_lap,\n",
    "                            map_shuffled, FRthr, shuffle_thr, min_width, valid_lap_num_thr,\n",
    "                            spatial_info, spatial_info_shuffled):\n",
    "    # Initialize\n",
    "    spatial_field1 = np.zeros_like(spatial_FR_map_session, dtype=int)\n",
    "    spatial_field2 = np.zeros_like(spatial_FR_map_session, dtype=int)\n",
    "    spatial_field3 = np.zeros_like(spatial_FR_map_session, dtype=int)\n",
    "\n",
    "\n",
    "   # Smooth\n",
    "    spatial_FR_map_session = gaussian_filter_segments(spatial_FR_map_session, sigma=2, axis=-1, mode='wrap')\n",
    "    map_shuffled = gaussian_filter_segments(map_shuffled, sigma=2, axis=-1, mode='wrap')\n",
    "\n",
    "    for neurons in range(len(spatial_FR_map_session)):\n",
    "        # Condition #1: Spatial FR > threshold of FR in all bins\n",
    "        tc = spatial_FR_map_session[neurons, :]\n",
    "        tc = tc > np.nanpercentile(tc, FRthr)\n",
    "        spatial_field1[neurons, :] = tc\n",
    "\n",
    "        # Condition #2: Spatial FR > threshold of shuffled map FR\n",
    "        spatial_field2[neurons, :] = spatial_FR_map_session[neurons, :] > np.nanpercentile(map_shuffled[:, neurons, :], shuffle_thr, axis=0)\n",
    "\n",
    "    spatial_field = spatial_field1 * spatial_field2\n",
    "\n",
    "    # Condition #4: Num of laps with spikes inside spatial field\n",
    "    max_fields = np.max([np.max(measure.label(spatial_field[n, :])) for n in range(len(spatial_field))])\n",
    "    valid_lap_num = np.zeros((len(spatial_FR_map_session), max_fields))\n",
    "    \n",
    "    for neurons in range(len(spatial_FR_map_session)):\n",
    "        tc2 = measure.label(spatial_field[neurons, :])  # Label connected components of 1s\n",
    "        for field in range(1, np.max(tc2) + 1):\n",
    "            field_ind = [ind[0] for ind in np.argwhere(tc2 == field)]\n",
    "            valid_lap_num[neurons, field - 1] = np.count_nonzero(np.nansum(spatial_FR_map_lap[neurons, :, field_ind], axis=1))\n",
    "            if valid_lap_num[neurons, field - 1] < valid_lap_num_thr:\n",
    "                tc2[tc2 == field] = 0\n",
    "        spatial_field3[neurons, :] = tc2 > 0\n",
    "\n",
    "    spatial_field = spatial_field * spatial_field3\n",
    "\n",
    "    # Condition #5: Spatial info\n",
    "    spatial_info_percentile = np.nanpercentile(spatial_info_shuffled, 95, axis=1)\n",
    "    for neurons in range(len(spatial_FR_map_session)):\n",
    "        if spatial_info[neurons] < spatial_info_percentile[neurons]:\n",
    "            spatial_field[neurons, :] = np.zeros_like(spatial_field[neurons, :])\n",
    "\n",
    "    # Final Condition: Remove fields smaller than min_width\n",
    "    for neurons in range(len(spatial_field)):\n",
    "        tc = measure.label(spatial_field[neurons, :])  # Label connected components of 1s\n",
    "        for field in range(1, np.max(tc) + 1):\n",
    "            if np.sum(tc == field) < min_width:\n",
    "                tc[tc == field] = 0\n",
    "        spatial_field[neurons, :] = tc > 0\n",
    "\n",
    "    return spatial_field\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbed8584",
   "metadata": {},
   "source": [
    "### Familiar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150d2c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "Position=df_downsample_familiar.Position.to_numpy()\n",
    "speed=df_downsample_familiar.Velocity.to_numpy()*3*0.224*100 #probably this 3 is length of track\n",
    "#dFF=dff_familiar[0]\n",
    "dFF_matrix=dff_familiar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b4bcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_index = filter_running(speed,lower_thresh=1,upper_thresh=10,sit_thresh=2,run_thresh=2) \n",
    "\n",
    "speed = speed[running_index] \n",
    "Position = Position[running_index] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b323f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dFF = np.zeros((len(dff_familiar), len(running_index)))\n",
    "for i in range(len(dff_familiar)):\n",
    "    dFF[i]=dff_familiar[i][running_index]\n",
    "dFF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27f02da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dFF_matrix = np.zeros((len(dff_familiar), len(running_index)))\n",
    "for i in range(len(dff_familiar)):\n",
    "    dFF_matrix[i]=dff_familiar[i][running_index]\n",
    "dFF_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1983ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store the results\n",
    "spatial_FR_map_sessions_familiar = []\n",
    "spatial_FR_map_laps_familiar = []\n",
    "time_spents_familiar = []\n",
    "lap_nums_familiar = []\n",
    "\n",
    "# Loop through each row of dFF\n",
    "for i in range(len(dFF)):\n",
    "    # Call the calculate_spatial_FR_map function with dFF[i] and other required parameters\n",
    "    spatial_FR_map_session, spatial_FR_map_lap, time_spent, lap_num = calculate_spatial_FR_map(Position, dFF[i], num_Spatial_Bins, frame_rate, trackLenth)\n",
    "    \n",
    "    # Append the results to the lists\n",
    "    spatial_FR_map_sessions_familiar.append(spatial_FR_map_session)\n",
    "    spatial_FR_map_laps_familiar.append(spatial_FR_map_lap)\n",
    "    time_spents_familiar.append(time_spent)\n",
    "    lap_nums_familiar.append(lap_num)\n",
    "\n",
    "# Convert lists to arrays if needed\n",
    "spatial_FR_map_sessions_familiar = np.array(spatial_FR_map_sessions_familiar)\n",
    "spatial_FR_map_laps_familiar = np.array(spatial_FR_map_laps_familiar)\n",
    "time_spents_familiar = np.array(time_spents_familiar)\n",
    "lap_nums_familiar = np.array(lap_nums_familiar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1eff82",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spatial_FR_map_laps_familiar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003fed49",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_spents_familiar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fea44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lap_nums_familiar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f6f362",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lap_nums_familiar[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295e6227",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spatial_occupancy_familiar = np.zeros((len(dff),num_Spatial_Bins))\n",
    "for i in range(len(dff)):\n",
    "    spatial_occupancy_familiar[i]=np.nansum(time_spents_familiar[i],axis=0)/np.nansum(time_spents_familiar[i])\n",
    "spatial_occupancy_familiar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5de52d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_info_familiar = np.zeros(len(spatial_FR_map_sessions_familiar))\n",
    "for i in range(len(spatial_FR_map_sessions_familiar)):\n",
    "    spatial_info_familiar[i]=calculate_spatial_info(spatial_FR_map_sessions_familiar[i],spatial_occupancy_familiar[i])\n",
    "spatial_info_familiar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e600f35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_times=1000\n",
    "spatial_info_shuffled_familiar,map_shuffled_familiar=shuffle_spike_count_by_lap(dFF_matrix,time_spents_familiar[0],lap_nums_familiar[0],shuffle_times,spatial_occupancy_familiar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424890ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FRthr = 0\n",
    "shuffle_thr = 95\n",
    "min_width = 3\n",
    "valid_lap_num_thr = max(lap_nums_familiar[0])*0.2\n",
    "\n",
    "spatial_field_familiar=calculate_spatial_field(spatial_FR_map_sessions_familiar,spatial_FR_map_laps_familiar,map_shuffled_familiar,FRthr,shuffle_thr,min_width,valid_lap_num_thr,\n",
    "                           spatial_info_familiar,spatial_info_shuffled_familiar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27944e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Determine the common y-axis limits\n",
    "all_data = np.concatenate(spatial_FR_map_sessions_familiar)\n",
    "y_min, y_max = np.nanmin(all_data), np.nanmax(all_data)\n",
    "\n",
    "# Create figure with reduced size\n",
    "plt.figure(figsize=[3, 2])  # Adjust the size as needed for a smaller figure\n",
    "\n",
    "# Loop through each lap\n",
    "for i in range(len(spatial_FR_map_sessions_familiar)):\n",
    "    # Create subplot with manual position adjustment\n",
    "    ax = plt.axes([0.1, 1 - (i + 1) * 0.07, 0.8, 0.07])  # Adjust position and size\n",
    "    \n",
    "    # Plot data with color based on spatial_field_familiar\n",
    "    data = spatial_FR_map_sessions_familiar[i]\n",
    "    field = spatial_field_familiar[i]\n",
    "\n",
    "    start_idx = 0\n",
    "    current_color = '#0344DF'\n",
    "\n",
    "    for j in range(1, len(data)):\n",
    "        if field[j] != field[start_idx]:\n",
    "            # Plot the segment with the current color\n",
    "            ax.plot(range(start_idx, j), data[start_idx:j], color=current_color)\n",
    "            # Update the start index\n",
    "            start_idx = j\n",
    "            # Update the color\n",
    "            current_color = 'red' if field[start_idx] == 1 else '#0344DF'\n",
    "\n",
    "    # Plot the last segment\n",
    "    ax.plot(range(start_idx, len(data)), data[start_idx:], color=current_color)\n",
    "\n",
    "    # Set the same y-axis limits for all subplots\n",
    "    ax.set_ylim([y_min, y_max])\n",
    "\n",
    "    # Remove border lines\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    \n",
    "    # Remove y-axis and x-axis ticks\n",
    "    ax.yaxis.set_ticks([])\n",
    "    ax.xaxis.set_ticks([])\n",
    "\n",
    "    # Add cell ID label on the left\n",
    "    ax.text(-0.1, 0.5, f'Cell {i}', transform=ax.transAxes, verticalalignment='center',size=7)\n",
    "\n",
    "# Adjust layout to reduce gaps between subplots\n",
    "plt.subplots_adjust(hspace=0.01)  # Adjust the space between subplots\n",
    "\n",
    "# Show the figure\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ed277b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_field_familiar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dd9593",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=[10,4]) \n",
    "    \n",
    "ax1.plot(spatial_FR_map_sessions_familiar[57], label=\"Mean Trace\",  color='#0344DF')\n",
    "\n",
    "plt.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    \n",
    "plt.legend(bbox_to_anchor=(0.93, 1.1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e9a1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=[10, 4])\n",
    "\n",
    "# Plot the data with color based on spatial_field\n",
    "data = spatial_FR_map_sessions_familiar[57]\n",
    "field = spatial_field_familiar[57]\n",
    "\n",
    "start_idx = 0\n",
    "current_color = '#0344DF'\n",
    "\n",
    "for i in range(1, len(data)):\n",
    "    if field[i] != field[start_idx]:\n",
    "        # Plot the segment with the current color\n",
    "        ax1.plot(range(start_idx, i), data[start_idx:i], color=current_color)\n",
    "        # Update the start index\n",
    "        start_idx = i\n",
    "        # Update the color\n",
    "        current_color = 'red' if field[start_idx] == 1 else '#0344DF'\n",
    "\n",
    "# Plot the last segment\n",
    "ax1.plot(range(start_idx, len(data)), data[start_idx:], color=current_color)\n",
    "\n",
    "plt.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6719d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of laps\n",
    "num_laps = len(spatial_FR_map_laps_familiar[0])\n",
    "\n",
    "# Create figure with reduced size\n",
    "plt.figure(figsize=[5, 3])  # Adjust the size as needed for a smaller figure\n",
    "\n",
    "# Loop through each lap\n",
    "for i in range(num_laps):\n",
    "    # Create subplot with manual position adjustment\n",
    "    ax = plt.axes([0.1, 1 - (i + 1) * 0.07, 0.8, 0.08])  # Adjust position and size\n",
    "\n",
    "    # Plot data\n",
    "    ax.plot(spatial_FR_map_laps_familiar[0][i], color='tab:orange', linewidth=1)  # Adjusted linewidth\n",
    "\n",
    "    # Remove border lines\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    \n",
    "    # Remove y-axis and x-axis ticks\n",
    "    ax.yaxis.set_ticks([])\n",
    "    ax.xaxis.set_ticks([])\n",
    "\n",
    "# Adjust layout\n",
    "plt.subplots_adjust(hspace=0.1)  # Adjust the space between subplots\n",
    "\n",
    "# Show the figure\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeba5a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Number of laps\n",
    "num_laps = len(spatial_FR_map_laps_familiar[0])\n",
    "\n",
    "# Create figure with reduced size\n",
    "plt.figure(figsize=[5, 3])  # Adjust the size as needed for a smaller figure\n",
    "\n",
    "# Loop through each lap\n",
    "for i in range(num_laps):\n",
    "    # Create subplot with manual position adjustment\n",
    "    ax = plt.axes([0.1, 1 - (i + 1) * 0.07, 0.8, 0.08])  # Adjust position and size\n",
    "\n",
    "    # Plot data\n",
    "    ax.plot(spatial_FR_map_laps_familiar[27][i], color='tab:orange', linewidth=1)  # Adjusted linewidth\n",
    "\n",
    "    # Remove border lines\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    \n",
    "    # Remove y-axis and x-axis ticks\n",
    "    ax.yaxis.set_ticks([])\n",
    "    ax.xaxis.set_ticks([])\n",
    "\n",
    "# Adjust layout\n",
    "plt.subplots_adjust(hspace=0.1)  # Adjust the space between subplots\n",
    "\n",
    "# Show the figure\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb77d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(spatial_field[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e998a9c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1d9f1f1",
   "metadata": {},
   "source": [
    "## Novel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39397b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Position=df_downsample_novel.Position.to_numpy()\n",
    "speed=df_downsample_novel.Velocity.to_numpy()*3*0.224*100 #probably this 3 is length of track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285503eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_index = filter_running(speed,lower_thresh=1,upper_thresh=10,sit_thresh=2,run_thresh=2) \n",
    "\n",
    "speed = speed[running_index] \n",
    "Position = Position[running_index] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cce9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dFF = np.zeros((len(dff_novel), len(running_index)))\n",
    "for i in range(len(dff_novel)):\n",
    "    dFF[i]=dff_novel[i][running_index]\n",
    "dFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fc69d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dFF_matrix = np.zeros((len(dff_familiar), len(running_index)))\n",
    "for i in range(len(dff_familiar)):\n",
    "    dFF_matrix[i]=dff_novel[i][running_index]\n",
    "dFF_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d1e546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store the results\n",
    "spatial_FR_map_sessions_novel = []\n",
    "spatial_FR_map_laps_novel = []\n",
    "time_spents_novel = []\n",
    "lap_nums_novel = []\n",
    "\n",
    "# Loop through each row of dFF\n",
    "for i in range(len(dFF)):\n",
    "    # Call the calculate_spatial_FR_map function with dFF[i] and other required parameters\n",
    "    spatial_FR_map_session, spatial_FR_map_lap, time_spent, lap_num = calculate_spatial_FR_map(Position, dFF[i], num_Spatial_Bins, frame_rate, trackLenth)\n",
    "    \n",
    "    # Append the results to the lists\n",
    "    spatial_FR_map_sessions_novel.append(spatial_FR_map_session)\n",
    "    spatial_FR_map_laps_novel.append(spatial_FR_map_lap)\n",
    "    time_spents_novel.append(time_spent)\n",
    "    lap_nums_novel.append(lap_num)\n",
    "\n",
    "# Convert lists to arrays if needed\n",
    "spatial_FR_map_sessions_novel = np.array(spatial_FR_map_sessions_novel)\n",
    "spatial_FR_map_laps_novel = np.array(spatial_FR_map_laps_novel)\n",
    "time_spents_novel = np.array(time_spents_novel)\n",
    "lap_nums_novel = np.array(lap_nums_novel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d0bf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_occupancy_novel = np.zeros((len(dff),num_Spatial_Bins))\n",
    "for i in range(len(dff)):\n",
    "    spatial_occupancy_novel[i]=np.nansum(time_spents_novel[i],axis=0)/np.nansum(time_spents_novel[i])\n",
    "spatial_occupancy_novel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d628993",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_info_novel = np.zeros(len(spatial_FR_map_sessions_novel))\n",
    "for i in range(len(spatial_FR_map_sessions_novel)):\n",
    "    spatial_info_novel[i]=calculate_spatial_info(spatial_FR_map_sessions_novel[i],spatial_occupancy_novel[i])\n",
    "spatial_info_novel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0752f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_times=1000\n",
    "spatial_info_shuffled_novel,map_shuffled_novel=shuffle_spike_count_by_lap(dFF_matrix,time_spents_novel[0],lap_nums_novel[0],shuffle_times,spatial_occupancy_novel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdc4a2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FRthr = 0\n",
    "shuffle_thr = 95\n",
    "min_width = 3\n",
    "valid_lap_num_thr = max(lap_nums_novel[0])*0.2\n",
    "\n",
    "spatial_field_novel=calculate_spatial_field(spatial_FR_map_sessions_novel,spatial_FR_map_laps_novel,map_shuffled_novel,FRthr,shuffle_thr,min_width,valid_lap_num_thr,\n",
    "                           spatial_info_novel,spatial_info_shuffled_novel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a088332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Determine the common y-axis limits\n",
    "all_data = np.concatenate(spatial_FR_map_sessions_novel)\n",
    "y_min, y_max = np.nanmin(all_data), np.nanmax(all_data)\n",
    "\n",
    "# Create figure with reduced size\n",
    "plt.figure(figsize=[3, 2])  # Adjust the size as needed for a smaller figure\n",
    "\n",
    "# Loop through each lap\n",
    "for i in range(len(spatial_FR_map_sessions_novel)):\n",
    "    # Create subplot with manual position adjustment\n",
    "    ax = plt.axes([0.1, 1 - (i + 1) * 0.07, 0.8, 0.07])  # Adjust position and size\n",
    "    \n",
    "    # Plot data with color based on spatial_field_novel\n",
    "    data = spatial_FR_map_sessions_novel[i]\n",
    "    field = spatial_field_novel[i]\n",
    "\n",
    "    start_idx = 0\n",
    "    current_color = '#0344DF'\n",
    "\n",
    "    for j in range(1, len(data)):\n",
    "        if field[j] != field[start_idx]:\n",
    "            # Plot the segment with the current color\n",
    "            ax.plot(range(start_idx, j), data[start_idx:j], color=current_color)\n",
    "            # Update the start index\n",
    "            start_idx = j\n",
    "            # Update the color\n",
    "            current_color = 'red' if field[start_idx] == 1 else '#0344DF'\n",
    "\n",
    "    # Plot the last segment\n",
    "    ax.plot(range(start_idx, len(data)), data[start_idx:], color=current_color)\n",
    "\n",
    "    # Set the same y-axis limits for all subplots\n",
    "    ax.set_ylim([y_min, y_max])\n",
    "\n",
    "    # Remove border lines\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    \n",
    "    # Remove y-axis and x-axis ticks\n",
    "    ax.yaxis.set_ticks([])\n",
    "    ax.xaxis.set_ticks([])\n",
    "\n",
    "    # Add cell ID label on the left\n",
    "    ax.text(-0.1, 0.5, f'Cell {i}', transform=ax.transAxes, verticalalignment='center',size=7)\n",
    "\n",
    "# Adjust layout to reduce gaps between subplots\n",
    "plt.subplots_adjust(hspace=0.01)  # Adjust the space between subplots\n",
    "\n",
    "# Show the figure\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dbd824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_familiar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fbf85f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import label\n",
    "\n",
    "def calculate_field_metrics(spatial_field):\n",
    "    num_cells, num_bins = spatial_field.shape\n",
    "    field_widths = np.zeros((num_cells, 1))\n",
    "    field_counts = np.zeros((num_cells, 1))\n",
    "\n",
    "    for cell in range(num_cells):\n",
    "        # Label contiguous regions of 1s\n",
    "        labeled_array, num_features = label(spatial_field[cell] == 1)\n",
    "        if num_features > 0:\n",
    "            # Calculate the width of each field\n",
    "            widths = [np.sum(labeled_array == feature) for feature in range(1, num_features + 1)]\n",
    "            field_widths[cell] = np.mean(widths)\n",
    "            field_counts[cell] = num_features\n",
    "    \n",
    "    return field_widths, field_counts\n",
    "\n",
    "def filter_cells(spatial_field_familiar, spatial_field_novel):\n",
    "    # Filter cells that have at least one 1 value in both datasets\n",
    "    valid_cells = np.where((spatial_field_familiar.sum(axis=1) > 0) & (spatial_field_novel.sum(axis=1) > 0))[0]\n",
    "    return spatial_field_familiar[valid_cells], spatial_field_novel[valid_cells], valid_cells\n",
    "\n",
    "def compare_field_metrics(field_widths_familiar, field_counts_familiar, field_widths_novel, field_counts_novel):\n",
    "    comparison_result = {\n",
    "        \"field_widths_familiar\": field_widths_familiar,\n",
    "        \"field_counts_familiar\": field_counts_familiar,\n",
    "        \"field_widths_novel\": field_widths_novel,\n",
    "        \"field_counts_novel\": field_counts_novel\n",
    "    }\n",
    "    return comparison_result\n",
    "\n",
    "\n",
    "# Filter out cells without any 1 values in both datasets\n",
    "filtered_familiar, filtered_novel, valid_cells = filter_cells(spatial_field_familiar, spatial_field_novel)\n",
    "\n",
    "# Calculate metrics for familiar data\n",
    "field_widths_familiar, field_counts_familiar = calculate_field_metrics(filtered_familiar)\n",
    "# Calculate metrics for novel data\n",
    "field_widths_novel, field_counts_novel = calculate_field_metrics(filtered_novel)\n",
    "\n",
    "# Compare the metrics\n",
    "comparison_result = compare_field_metrics(field_widths_familiar, field_counts_familiar, field_widths_novel, field_counts_novel)\n",
    "\n",
    "# Print the results for paired cells\n",
    "print(\"Comparison Result for Paired Cells:\")\n",
    "print(f\"Field Widths (Familiar): {comparison_result['field_widths_familiar']}\")\n",
    "print(f\"Field Widths (Novel): {comparison_result['field_widths_novel']}\")\n",
    "print(f\"Field Counts (Familiar): {comparison_result['field_counts_familiar']}\")\n",
    "print(f\"Field Counts (Novel): {comparison_result['field_counts_novel']}\")\n",
    "\n",
    "# Print valid cell indices\n",
    "print(\"Valid Cell Indices:\", valid_cells)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1362b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_field_metrics(spatial_field):\n",
    "    num_cells, num_bins = spatial_field.shape\n",
    "    field_widths = np.zeros((num_cells, 1))\n",
    "    field_counts = np.zeros((num_cells, 1))\n",
    "\n",
    "    for cell in range(num_cells):\n",
    "        # Label contiguous regions of 1s\n",
    "        labeled_array, num_features = label(spatial_field[cell] == 1)\n",
    "        if num_features > 0:\n",
    "            # Calculate the width of each field\n",
    "            widths = [np.sum(labeled_array == feature) for feature in range(1, num_features + 1)]\n",
    "            field_widths[cell] = np.mean(widths)\n",
    "            field_counts[cell] = num_features\n",
    "    \n",
    "    return field_widths, field_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7435967",
   "metadata": {},
   "outputs": [],
   "source": [
    "field_widths_familiar, field_counts_familiar = calculate_field_metrics(spatial_field_familiar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c201d70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "field_counts_familiar[field_counts_familiar>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0c6337",
   "metadata": {},
   "outputs": [],
   "source": [
    "field_widths_novel, field_counts_novel = calculate_field_metrics(spatial_field_novel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6714da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "field_counts_novel[field_counts_familiar>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a66d8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_width_familiar=field_widths_familiar[field_counts_familiar>1]\n",
    "grid_width_novel=field_widths_novel[field_counts_familiar>1]\n",
    "grid_count_familiar=field_counts_familiar[field_counts_familiar>1]\n",
    "grid_count_novel=field_counts_novel[field_counts_familiar>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5147ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('grid_width_familiar_P15.npy',grid_width_familiar)\n",
    "np.save('grid_width_novel_P15.npy',grid_width_novel)\n",
    "np.save('grid_count_familiar_P15.npy',grid_count_familiar)\n",
    "np.save('grid_count_novel_P15.npy',grid_count_novel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28382b32",
   "metadata": {},
   "source": [
    "### grid_cell_familiar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e5c17e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Filter cells based on the condition field_counts_familiar > 1\n",
    "valid_indices = np.where(field_counts_familiar > 1)[0]\n",
    "filtered_spatial_FR_map = [spatial_FR_map_sessions_familiar[i] for i in valid_indices]\n",
    "filtered_spatial_field = [spatial_field_familiar[i] for i in valid_indices]\n",
    "\n",
    "# Determine the common y-axis limits\n",
    "all_data = np.concatenate(filtered_spatial_FR_map)\n",
    "y_min, y_max = np.nanmin(all_data), np.nanmax(all_data)\n",
    "\n",
    "# Create figure with reduced size\n",
    "plt.figure(figsize=[3, 8])  # Adjust the size as needed for a smaller figure\n",
    "\n",
    "# Loop through each valid cell\n",
    "for i, (data, field) in enumerate(zip(filtered_spatial_FR_map, filtered_spatial_field)):\n",
    "    # Create subplot with manual position adjustment\n",
    "    ax = plt.axes([0.1, 1 - (i + 1) * 0.07, 0.8, 0.07])  # Adjust position and size\n",
    "    \n",
    "    start_idx = 0\n",
    "    current_color = '#0344DF'\n",
    "\n",
    "    for j in range(1, len(data)):\n",
    "        if field[j] != field[start_idx]:\n",
    "            # Plot the segment with the current color\n",
    "            ax.plot(range(start_idx, j), data[start_idx:j], color=current_color)\n",
    "            # Update the start index\n",
    "            start_idx = j\n",
    "            # Update the color\n",
    "            current_color = 'red' if field[start_idx] == 1 else '#0344DF'\n",
    "\n",
    "    # Plot the last segment\n",
    "    ax.plot(range(start_idx, len(data)), data[start_idx:], color=current_color)\n",
    "\n",
    "    # Set the same y-axis limits for all subplots\n",
    "    ax.set_ylim([y_min, y_max])\n",
    "\n",
    "    # Remove border lines\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    \n",
    "    # Remove y-axis and x-axis ticks\n",
    "    ax.yaxis.set_ticks([])\n",
    "    ax.xaxis.set_ticks([])\n",
    "\n",
    "    # Add cell ID label on the left\n",
    "    ax.text(-0.1, 0.5, f'Cell {valid_indices[i]}', transform=ax.transAxes, verticalalignment='center', size=7)\n",
    "\n",
    "# Adjust layout to reduce gaps between subplots\n",
    "plt.subplots_adjust(hspace=0.01)  # Adjust the space between subplots\n",
    "\n",
    "plt.savefig(\"BP1_grid_familiar.png\", format='png', dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c360c4",
   "metadata": {},
   "source": [
    "### grid_cell_novel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a92a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter cells based on the condition field_counts_familiar > 1\n",
    "valid_indices = np.where(field_counts_familiar > 1)[0]\n",
    "filtered_spatial_FR_map = [spatial_FR_map_sessions_novel[i] for i in valid_indices]\n",
    "filtered_spatial_field = [spatial_field_novel[i] for i in valid_indices]\n",
    "\n",
    "# Determine the common y-axis limits\n",
    "all_data = np.concatenate(filtered_spatial_FR_map)\n",
    "y_min, y_max = np.nanmin(all_data), np.nanmax(all_data)\n",
    "\n",
    "# Create figure with reduced size\n",
    "plt.figure(figsize=[3, 8])  # Adjust the size as needed for a smaller figure\n",
    "\n",
    "# Loop through each valid cell\n",
    "for i, (data, field) in enumerate(zip(filtered_spatial_FR_map, filtered_spatial_field)):\n",
    "    # Create subplot with manual position adjustment\n",
    "    ax = plt.axes([0.1, 1 - (i + 1) * 0.07, 0.8, 0.07])  # Adjust position and size\n",
    "    \n",
    "    start_idx = 0\n",
    "    current_color = '#0344DF'\n",
    "\n",
    "    for j in range(1, len(data)):\n",
    "        if field[j] != field[start_idx]:\n",
    "            # Plot the segment with the current color\n",
    "            ax.plot(range(start_idx, j), data[start_idx:j], color=current_color)\n",
    "            # Update the start index\n",
    "            start_idx = j\n",
    "            # Update the color\n",
    "            current_color = 'red' if field[start_idx] == 1 else '#0344DF'\n",
    "\n",
    "    # Plot the last segment\n",
    "    ax.plot(range(start_idx, len(data)), data[start_idx:], color=current_color)\n",
    "\n",
    "    # Set the same y-axis limits for all subplots\n",
    "    ax.set_ylim([y_min, y_max])\n",
    "\n",
    "    # Remove border lines\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    \n",
    "    # Remove y-axis and x-axis ticks\n",
    "    ax.yaxis.set_ticks([])\n",
    "    ax.xaxis.set_ticks([])\n",
    "\n",
    "    # Add cell ID label on the left\n",
    "    ax.text(-0.1, 0.5, f'Cell {valid_indices[i]}', transform=ax.transAxes, verticalalignment='center', size=7)\n",
    "\n",
    "# Adjust layout to reduce gaps between subplots\n",
    "plt.subplots_adjust(hspace=0.01)  # Adjust the space between subplots\n",
    "\n",
    "plt.savefig(\"BP1_grid_novel.png\", format='png', dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "\n",
    "# Show the figure\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11e5474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b4176c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4018d51",
   "metadata": {},
   "source": [
    "### Returned_Familiar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d06b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Position=df_downsample_Rfamiliar.Position.to_numpy()\n",
    "speed=df_downsample_Rfamiliar.Velocity.to_numpy()*3*0.224*100 #probably this 3 is length of track\n",
    "#dFF=dff_Rfamiliar[0]\n",
    "dFF_matrix=dff_Rfamiliar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1456c9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_index = filter_running(speed,lower_thresh=1,upper_thresh=10,sit_thresh=2,run_thresh=2) \n",
    "\n",
    "speed = speed[running_index] \n",
    "Position = Position[running_index] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2042b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dFF = np.zeros((len(dff_Rfamiliar), len(running_index)))\n",
    "for i in range(len(dff_Rfamiliar)):\n",
    "    dFF[i]=dff[i][running_index]\n",
    "dFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d33f914",
   "metadata": {},
   "outputs": [],
   "source": [
    "dFF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c083ac23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Position.shape)\n",
    "print(speed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3705d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store the results\n",
    "spatial_FR_map_sessions_Rfamiliar = []\n",
    "spatial_FR_map_laps_Rfamiliar = []\n",
    "time_spents_Rfamiliar = []\n",
    "lap_nums_Rfamiliar = []\n",
    "\n",
    "# Loop through each row of dFF\n",
    "for i in range(len(dFF)):\n",
    "    # Call the calculate_spatial_FR_map function with dFF[i] and other required parameters\n",
    "    spatial_FR_map_session, spatial_FR_map_lap, time_spent, lap_num = calculate_spatial_FR_map(Position, dFF[i], num_Spatial_Bins, frame_rate, trackLenth)\n",
    "    \n",
    "    # Append the results to the lists\n",
    "    spatial_FR_map_sessions_Rfamiliar.append(spatial_FR_map_session)\n",
    "    spatial_FR_map_laps_Rfamiliar.append(spatial_FR_map_lap)\n",
    "    time_spents_Rfamiliar.append(time_spent)\n",
    "    lap_nums_Rfamiliar.append(lap_num)\n",
    "\n",
    "# Convert lists to arrays if needed\n",
    "spatial_FR_map_sessions_Rfamiliar = np.array(spatial_FR_map_sessions_Rfamiliar)\n",
    "spatial_FR_map_laps_Rfamiliar = np.array(spatial_FR_map_laps_Rfamiliar)\n",
    "time_spents_Rfamiliar = np.array(time_spents_Rfamiliar)\n",
    "lap_nums_Rfamiliar = np.array(lap_nums_Rfamiliar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31498af4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spatial_FR_map_laps_Rfamiliar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed6c0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_occupancy_Rfamiliar = np.zeros((len(dff),num_Spatial_Bins))\n",
    "for i in range(len(dff)):\n",
    "    spatial_occupancy_Rfamiliar[i]=np.nansum(time_spents_Rfamiliar[i],axis=0)/np.nansum(time_spents_Rfamiliar[i])\n",
    "spatial_occupancy_Rfamiliar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8d255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_info_Rfamiliar = np.zeros(len(spatial_FR_map_sessions_Rfamiliar))\n",
    "for i in range(len(spatial_FR_map_sessions_Rfamiliar)):\n",
    "    spatial_info_Rfamiliar[i]=calculate_spatial_info(spatial_FR_map_sessions_Rfamiliar[i],spatial_occupancy_Rfamiliar[i])\n",
    "spatial_info_Rfamiliar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6200b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=[10,4]) \n",
    "    \n",
    "ax1.plot(spatial_FR_map_sessions_Rfamiliar[0], label=\"Mean Trace\",  color='#0344DF')\n",
    "\n",
    "plt.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    \n",
    "plt.legend(bbox_to_anchor=(0.93, 1.1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6e3e88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
